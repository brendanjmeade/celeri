{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%config InlineBackend.figure_format = \"retina\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-22T18:29:51.661926Z",
     "iopub.status.busy": "2021-08-22T18:29:51.661659Z",
     "iopub.status.idle": "2021-08-22T18:29:51.956035Z",
     "shell.execute_reply": "2021-08-22T18:29:51.955292Z",
     "shell.execute_reply.started": "2021-08-22T18:29:51.661900Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import addict\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from importlib import reload\n",
    "from typing import Dict\n",
    "\n",
    "import scipy.sparse\n",
    "import scipy.sparse.linalg\n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "import celeri"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read in data files and do basic processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Japan example\n",
    "command_file_name = \"../data/command/japan_command.json\"\n",
    "\n",
    "# Western North America example\n",
    "# command_file_name = \"../data/command/western_north_america_command.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "command = celeri.get_command(command_file_name)\n",
    "celeri.create_output_folder(command)\n",
    "logger = celeri.get_logger(command)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-22T18:29:53.570589Z",
     "iopub.status.busy": "2021-08-22T18:29:53.570331Z",
     "iopub.status.idle": "2021-08-22T18:30:09.817977Z",
     "shell.execute_reply": "2021-08-22T18:30:09.817443Z",
     "shell.execute_reply.started": "2021-08-22T18:29:53.570561Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "command, segment, block, meshes, station, mogi, sar = celeri.read_data(command_file_name)\n",
    "station = celeri.process_station(station, command)\n",
    "segment = celeri.process_segment(segment, command, meshes)\n",
    "sar = celeri.process_sar(sar, command)\n",
    "closure, block = celeri.assign_block_labels(segment, station, block, mogi, sar)\n",
    "assembly = addict.Dict()\n",
    "operators = addict.Dict()\n",
    "operators.meshes = [addict.Dict()] * len(meshes)\n",
    "assembly = celeri.merge_geodetic_data(assembly, station, sar) # Not sure this works correctly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get elastic operators and TDE smoothing operators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Okada partials for all segments\n",
    "celeri.get_elastic_operators_okada(operators, segment, station, command)\n",
    "\n",
    "# Get TDE smoothing operators\n",
    "celeri.get_all_mesh_smoothing_matrices(meshes, operators)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate non-elastic operators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "operators.rotation_to_velocities = celeri.get_rotation_to_velocities_partials(station)\n",
    "operators.global_float_block_rotation = celeri.get_global_float_block_rotation_partials(station)\n",
    "assembly, operators.block_motion_constraints = celeri.get_block_motion_constraints(assembly, block, command)\n",
    "assembly, operators.slip_rate_constraints = celeri.get_slip_rate_constraints(assembly, segment, block, command)\n",
    "operators.rotation_to_slip_rate = celeri.get_rotation_to_slip_rate_partials(segment, block)\n",
    "operators.block_strain_rate_to_velocities, strain_rate_block_index = celeri.get_block_strain_rate_to_velocities_partials(block, station, segment)\n",
    "operators.mogi_to_velocities = celeri.get_mogi_to_velocities_partials(mogi, station, command)\n",
    "operators.rotation_to_slip_rate_to_okada_to_velocities = operators.slip_rate_to_okada_to_velocities @ operators.rotation_to_slip_rate\n",
    "celeri.get_tde_slip_rate_constraints(meshes, operators)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "celeri.plot_input_summary(segment, station, block, meshes, mogi, sar, lon_range=command.lon_range, lat_range=command.lat_range, quiver_scale=command.quiver_scale)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate col_norms and H for each mesh here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = celeri.get_index(assembly, station, block, meshes)\n",
    "\n",
    "# Data and data weighting vector\n",
    "weighting_vector = celeri.get_weighting_vector(command, station, meshes, index)\n",
    "data_vector = celeri.get_data_vector(assembly, index)\n",
    "\n",
    "# Apply data weighting\n",
    "data_vector = data_vector * np.sqrt(weighting_vector)\n",
    "\n",
    "from celeri.hmatrix import build_hmatrix_from_mesh_tdes\n",
    "\n",
    "# Cast all block submatrices to sparse\n",
    "sparse_block_motion_okada_faults = csr_matrix(operators.rotation_to_velocities[index.station_row_keep_index, :] - operators.rotation_to_slip_rate_to_okada_to_velocities[index.station_row_keep_index, :])\n",
    "sparse_block_motion_constraints = csr_matrix(operators.block_motion_constraints)\n",
    "sparse_block_slip_rate_constraints = csr_matrix(operators.slip_rate_constraints)\n",
    "\n",
    "# Calculate column normalization vector for blocks\n",
    "operator_block_only = celeri.get_full_dense_operator_block_only(operators, index)\n",
    "weighting_vector_block_only = weighting_vector[0:operator_block_only.shape[0]][:, None]\n",
    "col_norms = np.linalg.norm(operator_block_only * np.sqrt(weighting_vector_block_only), axis=0)\n",
    "\n",
    "\n",
    "# Create lists for all TDE matrices per mesh\n",
    "H = []\n",
    "for i in range(len(meshes)):\n",
    "    # Get full TDE to velocity matrix for current mesh\n",
    "    tde_to_velocities = celeri.get_elastic_operator_single_mesh(meshes, station, command, i)\n",
    "    \n",
    "    # H-matrix representation\n",
    "    H.append(build_hmatrix_from_mesh_tdes(\n",
    "        meshes[i],\n",
    "        station,\n",
    "        -tde_to_velocities,\n",
    "        command.h_matrix_tol,\n",
    "        command.h_matrix_min_separation,\n",
    "        command.h_matrix_min_pts_per_box,\n",
    "    ))\n",
    "\n",
    "    print(f\"mesh {i} ({meshes[i].name}) H-matrix compression ratio: {H[i].report_compression_ratio():0.4f}\")\n",
    "\n",
    "    # Case smoothing matrices and tde slip rate constraints to sparse\n",
    "    smoothing_keep_index = celeri.get_keep_index_12(operators.smoothing_matrix[i].shape[0])\n",
    "    operators.smoothing_matrix[i] = csr_matrix(operators.smoothing_matrix[i][smoothing_keep_index, :][:, smoothing_keep_index])    \n",
    "    operators.tde_slip_rate_constraints[i] = csr_matrix(operators.tde_slip_rate_constraints[i])\n",
    "\n",
    "    # Eliminate unused columns and rows of TDE to velocity matrix\n",
    "    tde_to_velocities = np.delete(tde_to_velocities, np.arange(2, tde_to_velocities.shape[0], 3), axis=0)\n",
    "    tde_to_velocities = np.delete(tde_to_velocities, np.arange(2, tde_to_velocities.shape[1], 3), axis=1)\n",
    "\n",
    "    # Calculate column normalization vector current TDE mesh\n",
    "    weighting_vector_no_zero_rows = celeri.get_weighting_vector_single_mesh_for_col_norms(command, station, meshes, index, i)\n",
    "    current_tde_mesh_columns_full_no_zero_rows = np.vstack((-tde_to_velocities, operators.smoothing_matrix[i].toarray(), operators.tde_slip_rate_constraints[i].toarray())) * np.sqrt(weighting_vector_no_zero_rows[:, None])\n",
    "\n",
    "    # Concatenate everthing we need for col_norms\n",
    "    col_norms_current_tde_mesh = np.linalg.norm(current_tde_mesh_columns_full_no_zero_rows, axis=0)\n",
    "    col_norms = np.hstack((col_norms, col_norms_current_tde_mesh))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def matvec(v):\n",
    "# def matvec(v, all of the things):\n",
    "    \n",
    "    \"\"\" Build matvec (matrix vector product) operator for \n",
    "    scipy.sparse.linalg.LinearOperator.  This returns A * u\n",
    "\n",
    "    BJM: Should we be passing in: W, X, index, etc. or let them be known from the outer scope???\n",
    "    TBT: This will depend on how we integrate this into celeri and which\n",
    "    variable we're talking about. For example, we should stop using X.shape\n",
    "    entirely because that matrix won't exist in a fully sparse/hmatrix\n",
    "    implementation!\n",
    "    One design that I would probably lean towards\n",
    "    would be something like:\n",
    "    def build_sparse_hmatrix_linear_operator(operators,...):\n",
    "        sparse_block_motion_okada_faults = ...\n",
    "        define_other_precomputable_vars_here = ...\n",
    "\n",
    "        def matvec(v):\n",
    "            # use vars from the outer scope\n",
    "        def rmatvec(v):\n",
    "            # use vars from the outer scope\n",
    "\n",
    "        return scipy.sparse.linalg.LinearOperator(X.shape, matvec=matvec, rmatvec=rmatvec)\n",
    "        \n",
    "    Args:\n",
    "        u (nd.array): Candidate state vector\n",
    "\n",
    "    Returns:\n",
    "        out (nd.array): Predicted data vector\n",
    "    \"\"\"\n",
    "\n",
    "    # BJM: Weight the data vector\n",
    "    # TBT: It's important to remember to keep the input and output weighting\n",
    "    # conceptually separate since the \"out * np.sqrt(W)\" will actually change\n",
    "    # the solution to the least squares problem whereas the \"v / col_norms\"\n",
    "    # preconditioning step is a reversible change to the solution (which is the\n",
    "    # point since preconditioning should not change the solution!!)\n",
    "    v_scaled = v / col_norms \n",
    "\n",
    "    # Make storage for output\n",
    "    # out = np.zeros(X.shape[0])\n",
    "    out = np.zeros(index.n_operator_rows)\n",
    "    block_rotations = v_scaled[index.start_block_col : index.end_block_col]\n",
    "\n",
    "    # Okada\n",
    "    out[index.start_station_row : index.end_station_row] += sparse_block_motion_okada_faults.dot(block_rotations)\n",
    "\n",
    "    # Block motion constraints\n",
    "    out[index.start_block_constraints_row : index.end_block_constraints_row] += sparse_block_motion_constraints.dot(block_rotations)\n",
    "\n",
    "    # Slip rate constraints\n",
    "    out[index.start_slip_rate_constraints_row:index.end_slip_rate_constraints_row] += sparse_block_slip_rate_constraints.dot(block_rotations)\n",
    "\n",
    "    # Loop over TDE meshes\n",
    "    # for i in range(len(meshes)):\n",
    "    for i in range(len(meshes)):\n",
    "        tde_velocities = v_scaled[index.start_tde_col[i] : index.end_tde_col[i]]\n",
    "\n",
    "        # Insert TDE to velocity matrix\n",
    "        out[index.start_station_row : index.end_station_row] += H[i].dot(tde_velocities)\n",
    "\n",
    "        # TDE smoothing\n",
    "        out[index.start_tde_smoothing_row[i] : index.end_tde_smoothing_row[i]] += operators.smoothing_matrix[i].dot(tde_velocities)\n",
    "\n",
    "        # TDE slip rate constraints\n",
    "        out[index.start_tde_constraint_row[i] : index.end_tde_constraint_row[i]] += operators.tde_slip_rate_constraints[i].dot(tde_velocities)\n",
    "\n",
    "    # Weight!\n",
    "    return out * np.sqrt(weighting_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmatvec(u):\n",
    "    \"\"\" Build rmatvec (matrix vector product) operator for \n",
    "    scipy.sparse.linalg.LinearOperator.  This returns:\n",
    "    Returns A^H * v, where A^H is the conjugate transpose of A\n",
    "    for a candidate state vector, u.  We do this because\n",
    "    with the h-matrix approach we no longer have the full matrix\n",
    "    so we can't take the transpose all at once.\n",
    "\n",
    "    Args:\n",
    "        u (nd.array): Candidate state vector\n",
    "\n",
    "    Returns:\n",
    "        out (nd.array): Predicted data vector\n",
    "    \"\"\"\n",
    "\n",
    "    # Weight the data vector\n",
    "    u_weighted = u * np.sqrt(weighting_vector)\n",
    "\n",
    "    # Storage for output\n",
    "    # out = np.zeros(X.shape[1])\n",
    "    out = np.zeros(index.n_operator_cols)\n",
    "\n",
    "    # Select subset of weighted data for the observed velocities\n",
    "    station_rows = u_weighted[index.start_station_row : index.end_station_row]\n",
    "    block_constraints = u_weighted[index.start_block_constraints_row : index.end_block_constraints_row]\n",
    "\n",
    "    # Select subset of weighted data for the fault slip rate constraints\n",
    "    slip_rate_constraints = u_weighted[index.start_slip_rate_constraints_row : index.end_slip_rate_constraints_row]\n",
    "\n",
    "    # Okada and block rotation contribution to data vector\n",
    "    out[index.start_block_col : index.end_block_col] += station_rows @ sparse_block_motion_okada_faults\n",
    "\n",
    "    # Block motion constraints contribution to data vector\n",
    "    out[index.start_block_col : index.end_block_col] += block_constraints @ sparse_block_motion_constraints\n",
    "\n",
    "    # Fault slip rate constraints contribution to data vector\n",
    "    out[index.start_block_col : index.end_block_col] += slip_rate_constraints @ sparse_block_slip_rate_constraints\n",
    "\n",
    "    for i in range(len(meshes)):\n",
    "        # Select subset of weighted data for the TDE smoothing\n",
    "        tde_smoothing = u_weighted[index.start_tde_smoothing_row[i] : index.end_tde_smoothing_row[i]]\n",
    "\n",
    "        # Select subset of weighted data for the TDE slip rate constraints\n",
    "        tde_slip_rate = u_weighted[index.start_tde_constraint_row[i] : index.end_tde_constraint_row[i]]\n",
    "\n",
    "        # Hmatrix (TDEs to velocities)\n",
    "        out[index.start_tde_col[i] : index.end_tde_col[i]] += H[i].transpose_dot(station_rows)\n",
    "\n",
    "        # TDE smoothing contribution to data vector\n",
    "        out[index.start_tde_col[i] : index.end_tde_col[i]] += tde_smoothing @ operators.smoothing_matrix[i]\n",
    "\n",
    "        # TDE slip rate constraint contributions to data vector\n",
    "        out[index.start_tde_col[i] : index.end_tde_col[i]] += tde_slip_rate @ operators.tde_slip_rate_constraints[i]\n",
    "\n",
    "    # Weight\n",
    "    return out / col_norms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def matvec_wrapper(everything it needs):\n",
    "#     def matvec_caller(x):\n",
    "#         return matvec(everthing it needs, x)\n",
    "#     return matvec_caller\n",
    "# operator_hmatrix = scipy.sparse.linalg.LinearOperator((index.n_operator_rows, index.n_operator_cols), matvec=matvec_wrapper(everthing it needs), rmatvec=rmatvec)\n",
    "\n",
    "\n",
    "# Instantiate the scipy the linear operator for the iterative solver to use\n",
    "operator_hmatrix = scipy.sparse.linalg.LinearOperator((index.n_operator_rows, index.n_operator_cols), matvec=matvec, rmatvec=rmatvec)\n",
    "\n",
    "# Solve the linear system\n",
    "sparse_hmatrix_solution = scipy.sparse.linalg.lsmr(operator_hmatrix, data_vector, atol=command.atol, btol=command.btol)\n",
    "\n",
    "# Correct the solution for the col_norms preconditioning.\n",
    "sparse_hmatrix_state_vector = sparse_hmatrix_solution[0] / col_norms\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def post_process_estimation_hmatrix(\n",
    "    estimation_hmatrix: Dict, operators: Dict, station: pd.DataFrame, index: Dict\n",
    "):\n",
    "    \"\"\"Calculate derived values derived from the block model linear estimate (e.g., velocities, undertainties)\n",
    "\n",
    "    Args:\n",
    "        estimation (Dict): Estimated state vector and model covariance\n",
    "        operators (Dict): All linear operators\n",
    "        station (pd.DataFrame): GPS station data\n",
    "        index (Dict): Indices and counts of data and array sizes\n",
    "    \"\"\"\n",
    "\n",
    "    # estimation_hmatrix.predictions = estimation_hmatrix.operator @ (estimation_hmatrix.state_vector * col_norms)\n",
    "    estimation_hmatrix.predictions = matvec(estimation_hmatrix.state_vector * col_norms) / np.sqrt(estimation_hmatrix.weighting_vector)\n",
    "\n",
    "    estimation_hmatrix.vel = estimation_hmatrix.predictions[0 : 2 * index.n_stations]\n",
    "    estimation_hmatrix.east_vel = estimation_hmatrix.vel[0::2]\n",
    "    estimation_hmatrix.north_vel = estimation_hmatrix.vel[1::2]\n",
    "\n",
    "    # Calculate mean squared residual velocity\n",
    "    estimation_hmatrix.east_vel_residual = estimation_hmatrix.east_vel - station.east_vel\n",
    "    estimation_hmatrix.north_vel_residual = estimation_hmatrix.north_vel - station.north_vel\n",
    "\n",
    "    # Extract TDE slip rates from state vector\n",
    "    estimation_hmatrix.tde_rates = estimation_hmatrix.state_vector[\n",
    "        3 * index.n_blocks : 3 * index.n_blocks + 2 * index.n_tde_total\n",
    "    ]\n",
    "    estimation_hmatrix.tde_strike_slip_rates = estimation_hmatrix.tde_rates[0::2]\n",
    "    estimation_hmatrix.tde_dip_slip_rates = estimation_hmatrix.tde_rates[1::2]\n",
    "\n",
    "    # Extract segment slip rates from state vector\n",
    "    estimation_hmatrix.slip_rates = (\n",
    "        operators.rotation_to_slip_rate\n",
    "        @ estimation_hmatrix.state_vector[0 : 3 * index.n_blocks]\n",
    "    )\n",
    "    estimation_hmatrix.strike_slip_rates = estimation_hmatrix.slip_rates[0::3]\n",
    "    estimation_hmatrix.dip_slip_rates = estimation_hmatrix.slip_rates[1::3]\n",
    "    estimation_hmatrix.tensile_slip_rates = estimation_hmatrix.slip_rates[2::3]\n",
    "\n",
    "    estimation_hmatrix.strike_slip_rate_sigma = np.ones_like(estimation_hmatrix.strike_slip_rates)\n",
    "    estimation_hmatrix.dip_slip_rate_sigma = np.ones_like(estimation_hmatrix.dip_slip_rates)\n",
    "    estimation_hmatrix.tensile_slip_rate_sigma = np.ones_like(estimation_hmatrix.tensile_slip_rates)\n",
    "\n",
    "    # Calculate rotation only velocities\n",
    "    estimation_hmatrix.vel_rotation = (\n",
    "        operators.rotation_to_velocities[index.station_row_keep_index, :]\n",
    "        @ estimation_hmatrix.state_vector[0 : 3 * index.n_blocks]\n",
    "    )\n",
    "    estimation_hmatrix.east_vel_rotation = estimation_hmatrix.vel_rotation[0::2]\n",
    "    estimation_hmatrix.north_vel_rotation = estimation_hmatrix.vel_rotation[1::2]\n",
    "\n",
    "    # Calculate fully locked segment velocities\n",
    "    estimation_hmatrix.vel_elastic_segment = (\n",
    "        operators.rotation_to_slip_rate_to_okada_to_velocities[\n",
    "            index.station_row_keep_index, :\n",
    "        ]\n",
    "        @ estimation_hmatrix.state_vector[0 : 3 * index.n_blocks]\n",
    "    )\n",
    "    estimation_hmatrix.east_vel_elastic_segment = estimation_hmatrix.vel_elastic_segment[0::2]\n",
    "    estimation_hmatrix.north_vel_elastic_segment = estimation_hmatrix.vel_elastic_segment[1::2]\n",
    "\n",
    "    # TODO: Calculate block strain rate velocities\n",
    "    estimation_hmatrix.east_vel_block_strain_rate = np.zeros(len(station))\n",
    "    estimation_hmatrix.north_vel_block_strain_rate = np.zeros(len(station))\n",
    "\n",
    "    # Calculate TDE velocities    \n",
    "    estimation_hmatrix.vel_tde = np.zeros(2 * index.n_stations)\n",
    "    for i in range(len(meshes)):\n",
    "        estimation_hmatrix.vel_tde += (\n",
    "            H[i].dot(estimation_hmatrix.state_vector[index.start_tde_col[i] : index.end_tde_col[i]])\n",
    "        )\n",
    "    estimation_hmatrix.east_vel_tde = estimation_hmatrix.vel_tde[0::2]\n",
    "    estimation_hmatrix.north_vel_tde = estimation_hmatrix.vel_tde[1::2]\n",
    "\n",
    "\n",
    "estimation_hmatrix = addict.Dict()\n",
    "estimation_hmatrix.data_vector = data_vector\n",
    "estimation_hmatrix.weighting_vector = weighting_vector\n",
    "estimation_hmatrix.operator = operator_hmatrix\n",
    "estimation_hmatrix.state_vector = sparse_hmatrix_state_vector\n",
    "post_process_estimation_hmatrix(estimation_hmatrix, operators, station, index)\n",
    "celeri.plot_estimation_summary(segment, station, meshes, estimation_hmatrix, lon_range=command.lon_range, lat_range=command.lat_range, quiver_scale=command.quiver_scale)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# TODO: Need to move matvec and rmatvec to hmatrix.py\n",
    "# Also need to figure out what variables need to be passed to them explicitly\n",
    "# TODO: add write_output\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b49ecae73d9755d1e6525bca8f2b993ba748c0e2e7c79677d2e15f06ac3538b9"
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit ('celeri': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "4d250c5d35aa493295ca814fb3eaa1ee": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "6faf75ca5f3b41388f284e98ec2cf803": {
      "model_module": "jupyter-matplotlib",
      "model_module_version": "^0.9.0",
      "model_name": "ToolbarModel",
      "state": {
       "layout": "IPY_MODEL_9b061db2dc65459ca586b9b9f73c2362",
       "toolitems": [
        [
         "Home",
         "Reset original view",
         "home",
         "home"
        ],
        [
         "Back",
         "Back to previous view",
         "arrow-left",
         "back"
        ],
        [
         "Forward",
         "Forward to next view",
         "arrow-right",
         "forward"
        ],
        [
         "Pan",
         "Left button pans, Right button zooms\nx/y fixes axis, CTRL fixes aspect",
         "arrows",
         "pan"
        ],
        [
         "Zoom",
         "Zoom to rectangle\nx/y fixes axis, CTRL fixes aspect",
         "square-o",
         "zoom"
        ],
        [
         "Download",
         "Download plot",
         "floppy-o",
         "save_figure"
        ]
       ]
      }
     },
     "9b061db2dc65459ca586b9b9f73c2362": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "c25a38234e8f4e818670d9767f95a430": {
      "model_module": "jupyter-matplotlib",
      "model_module_version": "^0.9.0",
      "model_name": "MPLCanvasModel",
      "state": {
       "_cursor": "default",
       "_figure_label": "Figure 1",
       "_height": 708,
       "_width": 1746,
       "layout": "IPY_MODEL_4d250c5d35aa493295ca814fb3eaa1ee",
       "toolbar": "IPY_MODEL_6faf75ca5f3b41388f284e98ec2cf803",
       "toolbar_position": "left"
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
