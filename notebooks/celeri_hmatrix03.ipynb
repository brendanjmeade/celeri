{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%config InlineBackend.figure_format = \"retina\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-22T18:29:51.661926Z",
     "iopub.status.busy": "2021-08-22T18:29:51.661659Z",
     "iopub.status.idle": "2021-08-22T18:29:51.956035Z",
     "shell.execute_reply": "2021-08-22T18:29:51.955292Z",
     "shell.execute_reply.started": "2021-08-22T18:29:51.661900Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import addict\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from importlib import reload\n",
    "from typing import Dict\n",
    "\n",
    "import scipy.sparse\n",
    "import scipy.sparse.linalg\n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "import celeri"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read in data files and do basic processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Japan example\n",
    "command_file_name = \"../data/command/japan_command.json\"\n",
    "\n",
    "# Western North America example\n",
    "# command_file_name = \"../data/command/western_north_america_command.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-22T18:29:53.570589Z",
     "iopub.status.busy": "2021-08-22T18:29:53.570331Z",
     "iopub.status.idle": "2021-08-22T18:30:09.817977Z",
     "shell.execute_reply": "2021-08-22T18:30:09.817443Z",
     "shell.execute_reply.started": "2021-08-22T18:29:53.570561Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "command = celeri.get_command(command_file_name)\n",
    "celeri.create_output_folder(command)\n",
    "logger = celeri.get_logger(command)\n",
    "segment, block, meshes, station, mogi, sar = celeri.read_data(command)\n",
    "station = celeri.process_station(station, command)\n",
    "segment = celeri.process_segment(segment, command, meshes)\n",
    "sar = celeri.process_sar(sar, command)\n",
    "closure, block = celeri.assign_block_labels(segment, station, block, mogi, sar)\n",
    "assembly = addict.Dict()\n",
    "operators = addict.Dict()\n",
    "operators.meshes = [addict.Dict()] * len(meshes)\n",
    "assembly = celeri.merge_geodetic_data(assembly, station, sar) # Not sure this works correctly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get elastic operators and TDE smoothing operators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Okada partials for all segments\n",
    "celeri.get_elastic_operators_okada(operators, segment, station, command)\n",
    "\n",
    "# Get TDE smoothing operators\n",
    "celeri.get_all_mesh_smoothing_matrices(meshes, operators)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate non-elastic operators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "operators.rotation_to_velocities = celeri.get_rotation_to_velocities_partials(station)\n",
    "operators.global_float_block_rotation = celeri.get_global_float_block_rotation_partials(station)\n",
    "assembly, operators.block_motion_constraints = celeri.get_block_motion_constraints(assembly, block, command)\n",
    "assembly, operators.slip_rate_constraints = celeri.get_slip_rate_constraints(assembly, segment, block, command)\n",
    "operators.rotation_to_slip_rate = celeri.get_rotation_to_slip_rate_partials(segment, block)\n",
    "operators.block_strain_rate_to_velocities, strain_rate_block_index = celeri.get_block_strain_rate_to_velocities_partials(block, station, segment)\n",
    "operators.mogi_to_velocities = celeri.get_mogi_to_velocities_partials(mogi, station, command)\n",
    "operators.rotation_to_slip_rate_to_okada_to_velocities = operators.slip_rate_to_okada_to_velocities @ operators.rotation_to_slip_rate\n",
    "celeri.get_tde_slip_rate_constraints(meshes, operators)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "celeri.plot_input_summary(segment, station, block, meshes, mogi, sar, lon_range=command.lon_range, lat_range=command.lat_range, quiver_scale=command.quiver_scale)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate col_norms and H for each mesh here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = celeri.get_index(assembly, station, block, meshes)\n",
    "\n",
    "# Data and data weighting vector\n",
    "weighting_vector = celeri.get_weighting_vector(command, station, meshes, index)\n",
    "data_vector = celeri.get_data_vector(assembly, index)\n",
    "\n",
    "# Apply data weighting\n",
    "data_vector = data_vector * np.sqrt(weighting_vector)\n",
    "\n",
    "from celeri.hmatrix import build_hmatrix_from_mesh_tdes\n",
    "\n",
    "# Cast all block submatrices to sparse\n",
    "sparse_block_motion_okada_faults = csr_matrix(operators.rotation_to_velocities[index.station_row_keep_index, :] - operators.rotation_to_slip_rate_to_okada_to_velocities[index.station_row_keep_index, :])\n",
    "sparse_block_motion_constraints = csr_matrix(operators.block_motion_constraints)\n",
    "sparse_block_slip_rate_constraints = csr_matrix(operators.slip_rate_constraints)\n",
    "\n",
    "# Calculate column normalization vector for blocks\n",
    "operator_block_only = celeri.get_full_dense_operator_block_only(operators, index)\n",
    "weighting_vector_block_only = weighting_vector[0:operator_block_only.shape[0]][:, None]\n",
    "col_norms = np.linalg.norm(operator_block_only * np.sqrt(weighting_vector_block_only), axis=0)\n",
    "\n",
    "\n",
    "# Create lists for all TDE matrices per mesh\n",
    "H = []\n",
    "for i in range(len(meshes)):\n",
    "    # Get full TDE to velocity matrix for current mesh\n",
    "    tde_to_velocities = celeri.get_elastic_operator_single_mesh(meshes, station, command, i)\n",
    "    \n",
    "    # H-matrix representation\n",
    "    H.append(build_hmatrix_from_mesh_tdes(\n",
    "        meshes[i],\n",
    "        station,\n",
    "        -tde_to_velocities,\n",
    "        command.h_matrix_tol,\n",
    "        command.h_matrix_min_separation,\n",
    "        command.h_matrix_min_pts_per_box,\n",
    "    ))\n",
    "\n",
    "    logger.info(f\"mesh {i} ({meshes[i].name}) H-matrix compression ratio: {H[i].report_compression_ratio():0.4f}\")\n",
    "\n",
    "    # Case smoothing matrices and tde slip rate constraints to sparse\n",
    "    smoothing_keep_index = celeri.get_keep_index_12(operators.smoothing_matrix[i].shape[0])\n",
    "    operators.smoothing_matrix[i] = csr_matrix(operators.smoothing_matrix[i][smoothing_keep_index, :][:, smoothing_keep_index])    \n",
    "    operators.tde_slip_rate_constraints[i] = csr_matrix(operators.tde_slip_rate_constraints[i])\n",
    "\n",
    "    # Eliminate unused columns and rows of TDE to velocity matrix\n",
    "    tde_to_velocities = np.delete(tde_to_velocities, np.arange(2, tde_to_velocities.shape[0], 3), axis=0)\n",
    "    tde_to_velocities = np.delete(tde_to_velocities, np.arange(2, tde_to_velocities.shape[1], 3), axis=1)\n",
    "\n",
    "    # Calculate column normalization vector current TDE mesh\n",
    "    weighting_vector_no_zero_rows = celeri.get_weighting_vector_single_mesh_for_col_norms(command, station, meshes, index, i)\n",
    "    current_tde_mesh_columns_full_no_zero_rows = np.vstack((-tde_to_velocities, operators.smoothing_matrix[i].toarray(), operators.tde_slip_rate_constraints[i].toarray())) * np.sqrt(weighting_vector_no_zero_rows[:, None])\n",
    "\n",
    "    # Concatenate everthing we need for col_norms\n",
    "    col_norms_current_tde_mesh = np.linalg.norm(current_tde_mesh_columns_full_no_zero_rows, axis=0)\n",
    "    col_norms = np.hstack((col_norms, col_norms_current_tde_mesh))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Package parameters that matvec and rmatvec need for the iterative solve\n",
    "h_matrix_solve_parameters = (index,\n",
    "                             meshes,\n",
    "                             H,\n",
    "                             operators,\n",
    "                             weighting_vector,\n",
    "                             col_norms,\n",
    "                             sparse_block_motion_okada_faults,\n",
    "                             sparse_block_motion_constraints,\n",
    "                             sparse_block_slip_rate_constraints,\n",
    "                             )\n",
    "\n",
    "# Instantiate the scipy the linear operator for the iterative solver to use\n",
    "operator_hmatrix = scipy.sparse.linalg.LinearOperator((index.n_operator_rows, index.n_operator_cols), matvec=celeri.matvec_wrapper(h_matrix_solve_parameters), rmatvec=celeri.rmatvec_wrapper(h_matrix_solve_parameters))\n",
    "\n",
    "# Solve the linear system\n",
    "sparse_hmatrix_solution = scipy.sparse.linalg.lsmr(operator_hmatrix, data_vector, atol=command.atol, btol=command.btol)\n",
    "\n",
    "# Correct the solution for the col_norms preconditioning.\n",
    "sparse_hmatrix_state_vector = sparse_hmatrix_solution[0] / col_norms\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimation = addict.Dict()\n",
    "estimation.data_vector = data_vector\n",
    "estimation.weighting_vector = weighting_vector\n",
    "estimation.operator = operator_hmatrix\n",
    "estimation.state_vector = sparse_hmatrix_state_vector\n",
    "celeri.post_process_estimation_hmatrix(estimation, operators, meshes, H, station, index, col_norms, h_matrix_solve_parameters)\n",
    "celeri.write_output(command, estimation, station, segment, block, meshes)\n",
    "celeri.plot_estimation_summary(segment, station, meshes, estimation, lon_range=command.lon_range, lat_range=command.lat_range, quiver_scale=command.quiver_scale)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "residual_velocity_vector = np.concatenate((estimation.east_vel_residual.values, estimation.north_vel_residual.values))\n",
    "mean_average_error = np.mean(np.abs(residual_velocity_vector))\n",
    "mean_squared_error = np.sum(residual_velocity_vector**2.0) / residual_velocity_vector.size\n",
    "\n",
    "# Create histogram of residual velocities\n",
    "plt.figure()\n",
    "plt.hist(residual_velocity_vector, 50)\n",
    "plt.xlabel(\"residual velocity (mm/yr)\")\n",
    "plt.ylabel(\"N\")\n",
    "plt.title(f\"mae = {mean_average_error:.2f} (mm/yr), mse = {mean_squared_error:.2f} (mm/yr)^2\")\n",
    "plt.show()\n",
    "\n",
    "print(type(estimation.east_vel_residual))\n",
    "print(type(estimation.east_vel_residual.values))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b49ecae73d9755d1e6525bca8f2b993ba748c0e2e7c79677d2e15f06ac3538b9"
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit ('celeri': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "4d250c5d35aa493295ca814fb3eaa1ee": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "6faf75ca5f3b41388f284e98ec2cf803": {
      "model_module": "jupyter-matplotlib",
      "model_module_version": "^0.9.0",
      "model_name": "ToolbarModel",
      "state": {
       "layout": "IPY_MODEL_9b061db2dc65459ca586b9b9f73c2362",
       "toolitems": [
        [
         "Home",
         "Reset original view",
         "home",
         "home"
        ],
        [
         "Back",
         "Back to previous view",
         "arrow-left",
         "back"
        ],
        [
         "Forward",
         "Forward to next view",
         "arrow-right",
         "forward"
        ],
        [
         "Pan",
         "Left button pans, Right button zooms\nx/y fixes axis, CTRL fixes aspect",
         "arrows",
         "pan"
        ],
        [
         "Zoom",
         "Zoom to rectangle\nx/y fixes axis, CTRL fixes aspect",
         "square-o",
         "zoom"
        ],
        [
         "Download",
         "Download plot",
         "floppy-o",
         "save_figure"
        ]
       ]
      }
     },
     "9b061db2dc65459ca586b9b9f73c2362": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "c25a38234e8f4e818670d9767f95a430": {
      "model_module": "jupyter-matplotlib",
      "model_module_version": "^0.9.0",
      "model_name": "MPLCanvasModel",
      "state": {
       "_cursor": "default",
       "_figure_label": "Figure 1",
       "_height": 708,
       "_width": 1746,
       "layout": "IPY_MODEL_4d250c5d35aa493295ca814fb3eaa1ee",
       "toolbar": "IPY_MODEL_6faf75ca5f3b41388f284e98ec2cf803",
       "toolbar_position": "left"
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
