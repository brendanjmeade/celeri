{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%config InlineBackend.figure_format = \"retina\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import addict\n",
    "import matplotlib\n",
    "import sys\n",
    "import colorcet as cc\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.spatial import cKDTree\n",
    "\n",
    "from mpl_toolkits.axes_grid1.inset_locator import inset_axes\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "\n",
    "import celeri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_mesh(meshes, fill_value, ax):\n",
    "    x_coords = meshes.points[:, 0]\n",
    "    y_coords = meshes.points[:, 1]\n",
    "    vertex_array = np.asarray(meshes.verts)\n",
    "\n",
    "    if not ax:\n",
    "        ax = plt.gca()\n",
    "    xy = np.c_[x_coords, y_coords]\n",
    "    verts = xy[vertex_array]\n",
    "    pc = matplotlib.collections.PolyCollection(verts, edgecolor=\"none\", cmap=\"rainbow\")\n",
    "    pc.set_array(fill_value)\n",
    "    ax.add_collection(pc)\n",
    "    ax.autoscale()\n",
    "    plt.colorbar(pc, fraction=0.046, pad=0.04)\n",
    "\n",
    "    # Add mesh edge\n",
    "    x_edge = x_coords[meshes.ordered_edge_nodes[:, 0]]\n",
    "    y_edge = y_coords[meshes.ordered_edge_nodes[:, 0]]\n",
    "    x_edge = np.append(x_edge, x_coords[meshes.ordered_edge_nodes[0, 0]])\n",
    "    y_edge = np.append(y_edge, y_coords[meshes.ordered_edge_nodes[0, 0]])\n",
    "    plt.plot(x_edge, y_edge, color=\"black\", linewidth=1)\n",
    "    plt.gca().set_aspect(\"equal\")\n",
    "\n",
    "\n",
    "def smooth_irregular_data(x_coords, y_coords, values, length_scale):\n",
    "    # Build a KDTree for efficient neighbor searching\n",
    "    points = np.vstack((x_coords, y_coords)).T\n",
    "    tree = cKDTree(points)\n",
    "\n",
    "    # Prepare an array to store the smoothed values\n",
    "    smoothed_values = np.zeros_like(values)\n",
    "\n",
    "    # Smoothing calculation\n",
    "    for i, point in enumerate(points):\n",
    "        # Find neighbors within 3 * length_scale for efficiency\n",
    "        indices = tree.query_ball_point(point, 3 * length_scale)\n",
    "\n",
    "        # Calculate distances and apply Gaussian weights\n",
    "        distances = np.linalg.norm(points[indices] - point, axis=1)\n",
    "        weights = np.exp(-(distances**2) / (2 * length_scale**2))\n",
    "\n",
    "        # Weighted sum for smoothing\n",
    "        smoothed_values[i] = np.sum(weights * values[indices]) / np.sum(weights)\n",
    "\n",
    "    return smoothed_values\n",
    "\n",
    "\n",
    "def get_coupling(\n",
    "    x1,\n",
    "    x2,\n",
    "    estimated_slip,\n",
    "    kinematic_slip,\n",
    "    smoothing_length_scale,\n",
    "    kinematic_slip_regularization_scale,\n",
    "):\n",
    "    \"\"\"\n",
    "    Calculate coupling with optional smoothing and regularization\n",
    "    \"\"\"\n",
    "\n",
    "    # Smooth kinematic rates\n",
    "    if smoothing_length_scale > 0.0:\n",
    "        kinematic_slip = smooth_irregular_data(\n",
    "            x1,\n",
    "            x2,\n",
    "            kinematic_slip,\n",
    "            length_scale=smoothing_length_scale,\n",
    "        )\n",
    "\n",
    "    # Set the minimum value of the kinematic rates\n",
    "    # The purpose of this is to prevent coupling blow up as the kinematic\n",
    "    # rates approach zero\n",
    "    if kinematic_slip_regularization_scale > 0:\n",
    "        kinematic_slip[np.abs(kinematic_slip) < kinematic_slip_regularization_scale] = (\n",
    "            kinematic_slip_regularization_scale\n",
    "            * np.sign(\n",
    "                kinematic_slip[\n",
    "                    np.abs(kinematic_slip) < kinematic_slip_regularization_scale\n",
    "                ]\n",
    "            )\n",
    "        )\n",
    "\n",
    "    # Calculate coupling\n",
    "    coupling = estimated_slip / kinematic_slip\n",
    "    return coupling, kinematic_slip\n",
    "\n",
    "\n",
    "def update_slip_rate_bounds(\n",
    "    meshes,\n",
    "    mesh_idx,\n",
    "    tde_coupling_ss,\n",
    "    tde_coupling_ds,\n",
    "    kinematic_tde_rates_ss,\n",
    "    kinematic_tde_rates_ds,\n",
    "    current_ss_bounds_lower,\n",
    "    current_ss_bounds_upper,\n",
    "    current_ds_bounds_lower,\n",
    "    current_ds_bounds_upper,\n",
    "):\n",
    "    tde_coupling_ss_lower_oob_idx = np.where(\n",
    "        tde_coupling_ss < meshes[mesh_idx].qp_mesh_tde_slip_rate_lower_bound_ss_coupling\n",
    "    )[0]\n",
    "\n",
    "    tde_coupling_ss_upper_oob_idx = np.where(\n",
    "        tde_coupling_ss > meshes[mesh_idx].qp_mesh_tde_slip_rate_upper_bound_ss_coupling\n",
    "    )[0]\n",
    "\n",
    "    tde_coupling_ds_lower_oob_idx = np.where(\n",
    "        tde_coupling_ds < meshes[mesh_idx].qp_mesh_tde_slip_rate_lower_bound_ds_coupling\n",
    "    )[0]\n",
    "\n",
    "    tde_coupling_ds_upper_oob_idx = np.where(\n",
    "        tde_coupling_ds > meshes[mesh_idx].qp_mesh_tde_slip_rate_upper_bound_ds_coupling\n",
    "    )[0]\n",
    "\n",
    "    # Find indices of mesh elements with negative kinematic rate\n",
    "    neg_kinematic_ss_idx = np.where(kinematic_tde_rates_ss < 0)[0]\n",
    "    neg_kinematic_ds_idx = np.where(kinematic_tde_rates_ds < 0)[0]\n",
    "    pos_kinematic_ss_idx = np.where(kinematic_tde_rates_ss >= 0)[0]\n",
    "    pos_kinematic_ds_idx = np.where(kinematic_tde_rates_ds >= 0)[0]\n",
    "\n",
    "    # NEGATIVE CASE: Find intersection of indices with negative kinematic rates and OOB ss lower bounds\n",
    "    tde_coupling_ss_lower_oob_and_neg_kinematic_ss = np.intersect1d(\n",
    "        tde_coupling_ss_lower_oob_idx, neg_kinematic_ss_idx\n",
    "    )\n",
    "\n",
    "    # NEGATIVE CASE: Find intersection of indices with negative kinematic rates and OOB ss upper bounds\n",
    "    tde_coupling_ss_upper_oob_and_neg_kinematic_ss = np.intersect1d(\n",
    "        tde_coupling_ss_upper_oob_idx, neg_kinematic_ss_idx\n",
    "    )\n",
    "\n",
    "    # NEGATIVE CASE: Find intersection of indices with negative kinematic rates and OOB ds lower bounds\n",
    "    tde_coupling_ds_lower_oob_and_neg_kinematic_ds = np.intersect1d(\n",
    "        tde_coupling_ds_lower_oob_idx, neg_kinematic_ds_idx\n",
    "    )\n",
    "\n",
    "    # NEGATIVE CASE: Find intersection of indices with negative kinematic rates and OOB ds upper bounds\n",
    "    tde_coupling_ds_upper_oob_and_neg_kinematic_ds = np.intersect1d(\n",
    "        tde_coupling_ds_upper_oob_idx, neg_kinematic_ds_idx\n",
    "    )\n",
    "\n",
    "    # POSITIVE CASE: Find intersection of indices with positive kinematic rates and OOB ss lower bounds\n",
    "    tde_coupling_ss_lower_oob_and_pos_kinematic_ss = np.intersect1d(\n",
    "        tde_coupling_ss_lower_oob_idx, pos_kinematic_ss_idx\n",
    "    )\n",
    "\n",
    "    # POSITIVE CASE: Find intersection of indices with positive kinematic rates and OOB ss upper bounds\n",
    "    tde_coupling_ss_upper_oob_and_pos_kinematic_ss = np.intersect1d(\n",
    "        tde_coupling_ss_upper_oob_idx, pos_kinematic_ss_idx\n",
    "    )\n",
    "\n",
    "    # POSITIVE CASE: Find intersection of indices with positive kinematic rates and OOB ds lower bounds\n",
    "    tde_coupling_ds_lower_oob_and_pos_kinematic_ds = np.intersect1d(\n",
    "        tde_coupling_ds_lower_oob_idx, pos_kinematic_ds_idx\n",
    "    )\n",
    "\n",
    "    # POSITIVE CASE: Find intersection of indices with positive kinematic rates and OOB ds upper bounds\n",
    "    tde_coupling_ds_upper_oob_and_pos_kinematic_ds = np.intersect1d(\n",
    "        tde_coupling_ds_upper_oob_idx, pos_kinematic_ds_idx\n",
    "    )\n",
    "\n",
    "    # Calculate total number of OOB coupling constraints\n",
    "    n_oob = (\n",
    "        len(tde_coupling_ss_lower_oob_idx)\n",
    "        + len(tde_coupling_ss_upper_oob_idx)\n",
    "        + len(tde_coupling_ds_lower_oob_idx)\n",
    "        + len(tde_coupling_ds_upper_oob_idx)\n",
    "    )\n",
    "\n",
    "    # Make vectors for update slip rates (not neccesary but useful for debugging)\n",
    "    updated_ss_bounds_lower = np.copy(current_ss_bounds_lower)\n",
    "    updated_ss_bounds_upper = np.copy(current_ss_bounds_upper)\n",
    "    updated_ds_bounds_lower = np.copy(current_ds_bounds_lower)\n",
    "    updated_ds_bounds_upper = np.copy(current_ds_bounds_upper)\n",
    "\n",
    "    # Calculate midpoint slip rate assciated with midpoint coupling\n",
    "    mid_point_ss_coupling = 0.5 * (\n",
    "        meshes[mesh_idx].qp_mesh_tde_slip_rate_lower_bound_ss_coupling\n",
    "        + meshes[mesh_idx].qp_mesh_tde_slip_rate_upper_bound_ss_coupling\n",
    "    )\n",
    "    mid_point_ds_coupling = 0.5 * (\n",
    "        meshes[mesh_idx].qp_mesh_tde_slip_rate_lower_bound_ds_coupling\n",
    "        + meshes[mesh_idx].qp_mesh_tde_slip_rate_upper_bound_ds_coupling\n",
    "    )\n",
    "\n",
    "    mid_point_ss_rate = mid_point_ss_coupling * kinematic_tde_rates_ss\n",
    "    mid_point_ds_rate = mid_point_ds_coupling * kinematic_tde_rates_ds\n",
    "\n",
    "    # Update bounds with a linear approach towards midpoint\n",
    "    new_ss_bounds_lower = current_ss_bounds_lower + meshes[\n",
    "        mesh_idx\n",
    "    ].iterative_coupling_linear_slip_rate_reduction_factor * (\n",
    "        mid_point_ss_rate - current_ss_bounds_lower\n",
    "    )\n",
    "\n",
    "    new_ss_bounds_upper = current_ss_bounds_upper + meshes[\n",
    "        mesh_idx\n",
    "    ].iterative_coupling_linear_slip_rate_reduction_factor * (\n",
    "        mid_point_ss_rate - current_ss_bounds_upper\n",
    "    )\n",
    "\n",
    "    new_ds_bounds_lower = current_ds_bounds_lower + meshes[\n",
    "        mesh_idx\n",
    "    ].iterative_coupling_linear_slip_rate_reduction_factor * (\n",
    "        mid_point_ds_rate - current_ds_bounds_lower\n",
    "    )\n",
    "\n",
    "    new_ds_bounds_upper = current_ds_bounds_upper + meshes[\n",
    "        mesh_idx\n",
    "    ].iterative_coupling_linear_slip_rate_reduction_factor * (\n",
    "        mid_point_ds_rate - current_ds_bounds_upper\n",
    "    )\n",
    "\n",
    "    # Update slip rate bounds\n",
    "    # NOTE: Note upper and lower swap here for negative kinmatic cases (2nd and 3rd quadrants)\n",
    "    # Negative kinematic case\n",
    "    updated_ss_bounds_lower[tde_coupling_ss_upper_oob_and_neg_kinematic_ss] = (\n",
    "        new_ss_bounds_lower[tde_coupling_ss_upper_oob_and_neg_kinematic_ss]\n",
    "    )\n",
    "    updated_ss_bounds_upper[tde_coupling_ss_lower_oob_and_neg_kinematic_ss] = (\n",
    "        new_ss_bounds_upper[tde_coupling_ss_lower_oob_and_neg_kinematic_ss]\n",
    "    )\n",
    "    updated_ds_bounds_lower[tde_coupling_ds_upper_oob_and_neg_kinematic_ds] = (\n",
    "        new_ds_bounds_lower[tde_coupling_ds_upper_oob_and_neg_kinematic_ds]\n",
    "    )\n",
    "    updated_ds_bounds_upper[tde_coupling_ds_lower_oob_and_neg_kinematic_ds] = (\n",
    "        new_ds_bounds_upper[tde_coupling_ds_lower_oob_and_neg_kinematic_ds]\n",
    "    )\n",
    "\n",
    "    # Positive kinematic case\n",
    "    updated_ss_bounds_lower[tde_coupling_ss_lower_oob_and_pos_kinematic_ss] = (\n",
    "        new_ss_bounds_lower[tde_coupling_ss_lower_oob_and_pos_kinematic_ss]\n",
    "    )\n",
    "    updated_ss_bounds_upper[tde_coupling_ss_upper_oob_and_pos_kinematic_ss] = (\n",
    "        new_ss_bounds_upper[tde_coupling_ss_upper_oob_and_pos_kinematic_ss]\n",
    "    )\n",
    "    updated_ds_bounds_lower[tde_coupling_ds_lower_oob_and_pos_kinematic_ds] = (\n",
    "        new_ds_bounds_lower[tde_coupling_ds_lower_oob_and_pos_kinematic_ds]\n",
    "    )\n",
    "    updated_ds_bounds_upper[tde_coupling_ds_upper_oob_and_pos_kinematic_ds] = (\n",
    "        new_ds_bounds_upper[tde_coupling_ds_upper_oob_and_pos_kinematic_ds]\n",
    "    )\n",
    "\n",
    "    return (\n",
    "        n_oob,\n",
    "        updated_ss_bounds_lower,\n",
    "        updated_ss_bounds_upper,\n",
    "        updated_ds_bounds_lower,\n",
    "        updated_ds_bounds_upper,\n",
    "    )\n",
    "\n",
    "\n",
    "def check_coupling_bounds_single_mesh(\n",
    "    operators,\n",
    "    index,\n",
    "    meshes,\n",
    "    mesh_idx,\n",
    "    estimation_qp,\n",
    "    current_ss_bounds_lower,\n",
    "    current_ss_bounds_upper,\n",
    "    current_ds_bounds_lower,\n",
    "    current_ds_bounds_upper,\n",
    "):\n",
    "    # Get kinematic rates on mesh elements\n",
    "    kinematic_tde_rates = (\n",
    "        operators.rotation_to_tri_slip_rate[mesh_idx]\n",
    "        @ estimation_qp.state_vector[0 : 3 * len(block)]\n",
    "    )\n",
    "\n",
    "    # Get estimated elastic rates on mesh elements\n",
    "    estimated_tde_rates = (\n",
    "        operators.eigenvectors_to_tde_slip[mesh_idx]\n",
    "        @ estimation_qp.state_vector[\n",
    "            index.start_col_eigen[mesh_idx] : index.end_col_eigen[mesh_idx]\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # Calculate strike-slip and dip-slip coupling\n",
    "    tde_coupling_ss, kinematic_tde_rates_ss_smooth = get_coupling(\n",
    "        meshes[mesh_idx].lon_centroid,\n",
    "        meshes[mesh_idx].lat_centroid,\n",
    "        estimated_tde_rates[0::2],\n",
    "        kinematic_tde_rates[0::2],\n",
    "        smoothing_length_scale=meshes[\n",
    "            mesh_idx\n",
    "        ].iterative_coupling_smoothing_length_scale,\n",
    "        kinematic_slip_regularization_scale=meshes[\n",
    "            mesh_idx\n",
    "        ].iterative_coupling_kinematic_slip_regularization_scale,\n",
    "    )\n",
    "\n",
    "    tde_coupling_ds, kinematic_tde_rates_ds_smooth = get_coupling(\n",
    "        meshes[mesh_idx].lon_centroid,\n",
    "        meshes[mesh_idx].lat_centroid,\n",
    "        estimated_tde_rates[1::2],\n",
    "        kinematic_tde_rates[1::2],\n",
    "        smoothing_length_scale=meshes[\n",
    "            mesh_idx\n",
    "        ].iterative_coupling_smoothing_length_scale,\n",
    "        kinematic_slip_regularization_scale=meshes[\n",
    "            mesh_idx\n",
    "        ].iterative_coupling_kinematic_slip_regularization_scale,\n",
    "    )\n",
    "\n",
    "    # Update slip rate bounds\n",
    "    (\n",
    "        n_oob,\n",
    "        updated_ss_bounds_lower,\n",
    "        updated_ss_bounds_upper,\n",
    "        updated_ds_bounds_lower,\n",
    "        updated_ds_bounds_upper,\n",
    "    ) = update_slip_rate_bounds(\n",
    "        meshes,\n",
    "        mesh_idx,\n",
    "        tde_coupling_ss,\n",
    "        tde_coupling_ds,\n",
    "        kinematic_tde_rates_ss_smooth,\n",
    "        kinematic_tde_rates_ds_smooth,\n",
    "        current_ss_bounds_lower,\n",
    "        current_ss_bounds_upper,\n",
    "        current_ds_bounds_lower,\n",
    "        current_ds_bounds_upper,\n",
    "    )\n",
    "\n",
    "    return (\n",
    "        updated_ss_bounds_lower,\n",
    "        updated_ss_bounds_upper,\n",
    "        updated_ds_bounds_lower,\n",
    "        updated_ds_bounds_upper,\n",
    "        kinematic_tde_rates_ss_smooth,\n",
    "        kinematic_tde_rates_ds_smooth,\n",
    "        estimated_tde_rates[0::2],\n",
    "        estimated_tde_rates[1::2],\n",
    "        n_oob,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read data and pre-process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "COMMAND_FILE_NAME = \"../data/command/japan_command_cmi_coupling.json\"\n",
    "command = celeri.get_command(COMMAND_FILE_NAME)\n",
    "celeri.create_output_folder(command)\n",
    "logger = celeri.get_logger(command)\n",
    "segment, block, meshes, station, mogi, sar = celeri.read_data(command)\n",
    "station = celeri.process_station(station, command)\n",
    "segment = celeri.process_segment(segment, command, meshes)\n",
    "sar = celeri.process_sar(sar, command)\n",
    "closure, block = celeri.assign_block_labels(segment, station, block, mogi, sar)\n",
    "assembly = addict.Dict()\n",
    "operators = addict.Dict()\n",
    "operators.meshes = [addict.Dict()] * len(meshes)\n",
    "assembly = celeri.merge_geodetic_data(assembly, station, sar)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate all operators, weighting, and data vector for KL+QP problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all elastic operators for segments and TDEs\n",
    "celeri.get_elastic_operators(operators, meshes, segment, station, command)\n",
    "\n",
    "# Get TDE smoothing operators\n",
    "celeri.get_all_mesh_smoothing_matrices(meshes, operators)\n",
    "\n",
    "# Block rotation to velocity operator\n",
    "operators.rotation_to_velocities = celeri.get_rotation_to_velocities_partials(\n",
    "    station, len(block)\n",
    ")\n",
    "\n",
    "# Soft block motion constraints\n",
    "assembly, operators.block_motion_constraints = celeri.get_block_motion_constraints(\n",
    "    assembly, block, command\n",
    ")\n",
    "\n",
    "# Soft slip rate constraints\n",
    "assembly, operators.slip_rate_constraints = celeri.get_slip_rate_constraints(\n",
    "    assembly, segment, block, command\n",
    ")\n",
    "\n",
    "# Rotation vectors to slip rate operator\n",
    "operators.rotation_to_slip_rate = celeri.get_rotation_to_slip_rate_partials(\n",
    "    segment, block\n",
    ")\n",
    "\n",
    "# Internal block strain rate operator\n",
    "(\n",
    "    operators.block_strain_rate_to_velocities,\n",
    "    strain_rate_block_index,\n",
    ") = celeri.get_block_strain_rate_to_velocities_partials(block, station, segment)\n",
    "\n",
    "# Mogi source operator\n",
    "operators.mogi_to_velocities = celeri.get_mogi_to_velocities_partials(\n",
    "    mogi, station, command\n",
    ")\n",
    "\n",
    "# Soft TDE boundary condition constraints\n",
    "celeri.get_tde_slip_rate_constraints(meshes, operators)\n",
    "\n",
    "# Get index\n",
    "index = celeri.get_index_eigen(assembly, segment, station, block, meshes, mogi)\n",
    "\n",
    "# Get data vector for KL problem\n",
    "data_vector_eigen = celeri.get_data_vector_eigen(meshes, assembly, index)\n",
    "\n",
    "# Get data vector for KL problem\n",
    "weighting_vector_eigen = celeri.get_weighting_vector_eigen(\n",
    "    command, station, meshes, index\n",
    ")\n",
    "\n",
    "# Get KL modes for each mesh\n",
    "celeri.get_eigenvectors_to_tde_slip(operators, meshes)\n",
    "\n",
    "# Get full operator including all blocks, KL modes, strain blocks, and mogis\n",
    "operators.eigen = celeri.get_full_dense_operator_eigen(operators, meshes, index)\n",
    "\n",
    "# Get rotation to TDE kinematic slip rate operator for all meshes tied to segments\n",
    "celeri.get_tde_coupling_constraints(meshes, segment, block, operators)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Solve bounded KL+QP problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get QP bounds as inequality constraints\n",
    "qp_inequality_constraints_matrix, qp_inequality_constraints_data_vector = (\n",
    "    celeri.get_qp_all_inequality_operator_and_data_vector(\n",
    "        index, meshes, operators, segment, block\n",
    "    )\n",
    ")\n",
    "\n",
    "# QP solve\n",
    "opts = {\"show_progress\": True}\n",
    "solution_qp = celeri.lsqlin_qp(\n",
    "    operators.eigen * np.sqrt(weighting_vector_eigen[:, None]),\n",
    "    data_vector_eigen * np.sqrt(weighting_vector_eigen),\n",
    "    0,\n",
    "    qp_inequality_constraints_matrix,  # Inequality matrix\n",
    "    qp_inequality_constraints_data_vector,  # Inequality data vector\n",
    "    None,\n",
    "    None,\n",
    "    None,\n",
    "    None,\n",
    "    None,\n",
    "    opts,\n",
    ")\n",
    "\n",
    "\n",
    "# Create estimation data structure and calculate derived quantities\n",
    "estimation_qp = addict.Dict()\n",
    "estimation_qp.state_vector = np.array(solution_qp[\"x\"]).flatten()\n",
    "estimation_qp.operator = operators.eigen\n",
    "celeri.post_process_estimation_eigen(estimation_qp, operators, station, index)\n",
    "celeri.write_output(command, estimation_qp, station, segment, block, meshes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot KL+QP estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "celeri.plot_estimation_summary(\n",
    "    command,\n",
    "    segment,\n",
    "    station,\n",
    "    meshes,\n",
    "    estimation_qp,\n",
    "    lon_range=command.lon_range,\n",
    "    lat_range=command.lat_range,\n",
    "    quiver_scale=command.quiver_scale,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Iterative coupling: iteration loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get total number of segment meshes\n",
    "n_segment_meshes = np.max(segment.patch_file_name).astype(int) + 1\n",
    "\n",
    "# Count total number of triangles in segment meshes\n",
    "n_segment_meshes_tri = 0\n",
    "for i in range(n_segment_meshes):\n",
    "    n_segment_meshes_tri += meshes[i].n_tde\n",
    "\n",
    "# Create initial mesh slip rate bound arrays\n",
    "current_ss_bounds_lower = [None] * n_segment_meshes\n",
    "current_ss_bounds_upper = [None] * n_segment_meshes\n",
    "current_ds_bounds_lower = [None] * n_segment_meshes\n",
    "current_ds_bounds_upper = [None] * n_segment_meshes\n",
    "for i in range(n_segment_meshes):\n",
    "    current_ss_bounds_lower[i] = meshes[\n",
    "        i\n",
    "    ].qp_mesh_tde_slip_rate_lower_bound_ss * np.ones(meshes[i].n_tde)\n",
    "    current_ss_bounds_upper[i] = meshes[\n",
    "        i\n",
    "    ].qp_mesh_tde_slip_rate_upper_bound_ss * np.ones(meshes[i].n_tde)\n",
    "    current_ds_bounds_lower[i] = meshes[\n",
    "        i\n",
    "    ].qp_mesh_tde_slip_rate_lower_bound_ds * np.ones(meshes[i].n_tde)\n",
    "    current_ds_bounds_upper[i] = meshes[\n",
    "        i\n",
    "    ].qp_mesh_tde_slip_rate_upper_bound_ds * np.ones(meshes[i].n_tde)\n",
    "\n",
    "# Storage for number of OOB coupling values per mesh\n",
    "n_oob_vec = np.zeros((n_segment_meshes, 1))\n",
    "\n",
    "# Initialize lists and arrays for storing various slip rates\n",
    "store_ss_lower = [None] * n_segment_meshes\n",
    "store_ss_upper = [None] * n_segment_meshes\n",
    "store_ds_lower = [None] * n_segment_meshes\n",
    "store_ds_upper = [None] * n_segment_meshes\n",
    "store_ss_kinematic = [None] * n_segment_meshes\n",
    "store_ss_elcon = [None] * n_segment_meshes\n",
    "store_ds_kinematic = [None] * n_segment_meshes\n",
    "store_ds_elcon = [None] * n_segment_meshes\n",
    "for i in range(n_segment_meshes):\n",
    "    store_ss_lower[i] = np.zeros((meshes[i].n_tde, command.coupling_bounds_max_iter))\n",
    "    store_ss_upper[i] = np.zeros((meshes[i].n_tde, command.coupling_bounds_max_iter))\n",
    "    store_ds_lower[i] = np.zeros((meshes[i].n_tde, command.coupling_bounds_max_iter))\n",
    "    store_ds_upper[i] = np.zeros((meshes[i].n_tde, command.coupling_bounds_max_iter))\n",
    "    store_ss_kinematic[i] = np.zeros(\n",
    "        (meshes[i].n_tde, command.coupling_bounds_max_iter)\n",
    "    )\n",
    "    store_ss_elcon[i] = np.zeros((meshes[i].n_tde, command.coupling_bounds_max_iter))\n",
    "    store_ds_kinematic[i] = np.zeros(\n",
    "        (meshes[i].n_tde, command.coupling_bounds_max_iter)\n",
    "    )\n",
    "    store_ds_elcon[i] = np.zeros((meshes[i].n_tde, command.coupling_bounds_max_iter))\n",
    "\n",
    "# Variables for tracking overall convergence\n",
    "tde_total = 0\n",
    "for i in range(3):\n",
    "    tde_total += meshes[i].n_tde\n",
    "total_percentages = list()\n",
    "\n",
    "# Coupling bound iteration\n",
    "continue_iterating = True\n",
    "i = 0\n",
    "while continue_iterating:\n",
    "    # Create storage for updates slip rate constraints\n",
    "    updated_qp_inequality_constraints_data_vector = np.copy(\n",
    "        qp_inequality_constraints_data_vector\n",
    "    )\n",
    "\n",
    "    # Create storage for n OOB\n",
    "    current_noob = np.zeros((n_segment_meshes, 1))\n",
    "\n",
    "    # Loop over meshes\n",
    "    for j in range(n_segment_meshes):\n",
    "        (\n",
    "            updated_ss_bounds_lower,\n",
    "            updated_ss_bounds_upper,\n",
    "            updated_ds_bounds_lower,\n",
    "            updated_ds_bounds_upper,\n",
    "            kinematic_tde_rates_ss,\n",
    "            kinematic_tde_rates_ds,\n",
    "            estimated_tde_rates_ss,\n",
    "            estimated_tde_rates_ds,\n",
    "            n_oob,\n",
    "        ) = check_coupling_bounds_single_mesh(\n",
    "            operators,\n",
    "            index,\n",
    "            meshes,\n",
    "            j,  # This is the mesh index\n",
    "            estimation_qp,\n",
    "            current_ss_bounds_lower[j],\n",
    "            current_ss_bounds_upper[j],\n",
    "            current_ds_bounds_lower[j],\n",
    "            current_ds_bounds_upper[j],\n",
    "        )\n",
    "        logger.info(f\"Iteration: {i}, Mesh: {j}, NOOB: {n_oob}\")\n",
    "\n",
    "        # Store total number of OOB elements at this iteration step\n",
    "        n_oob_vec[j, i] = n_oob\n",
    "\n",
    "        # Build and insert update slip rate bounds into QP inequality vector\n",
    "        updated_lower_bounds = -1.0 * celeri.interleave2(\n",
    "            updated_ss_bounds_lower, updated_ds_bounds_lower\n",
    "        )\n",
    "        updated_upper_bounds = celeri.interleave2(\n",
    "            updated_ss_bounds_upper, updated_ds_bounds_upper\n",
    "        )\n",
    "        updated_bounds = np.hstack((updated_lower_bounds, updated_upper_bounds))\n",
    "\n",
    "        # Insert TDE lower bounds into QP constraint data vector\n",
    "        updated_qp_inequality_constraints_data_vector[\n",
    "            index.qp_constraint_tde_rate_start_row_eigen[\n",
    "                j\n",
    "            ] : index.qp_constraint_tde_rate_start_row_eigen[j]\n",
    "            + 2 * index.n_tde[j]\n",
    "        ] = updated_lower_bounds\n",
    "\n",
    "        # Insert TDE upper bounds into QP constraint data vector\n",
    "        updated_qp_inequality_constraints_data_vector[\n",
    "            index.qp_constraint_tde_rate_start_row_eigen[j]\n",
    "            + 2 * index.n_tde[j] : index.qp_constraint_tde_rate_end_row_eigen[j]\n",
    "        ] = updated_upper_bounds\n",
    "\n",
    "        # Set *updated* to *current* for next iteration\n",
    "        current_ss_bounds_lower[j] = np.copy(updated_ss_bounds_lower)\n",
    "        current_ss_bounds_upper[j] = np.copy(updated_ss_bounds_upper)\n",
    "        current_ds_bounds_lower[j] = np.copy(updated_ds_bounds_lower)\n",
    "        current_ds_bounds_upper[j] = np.copy(updated_ds_bounds_upper)\n",
    "\n",
    "        # Store values for visualization and debugging\n",
    "        store_ss_lower[j][:, i] = current_ss_bounds_lower[j]\n",
    "        store_ss_upper[j][:, i] = current_ss_bounds_upper[j]\n",
    "        store_ds_lower[j][:, i] = current_ds_bounds_lower[j]\n",
    "        store_ds_upper[j][:, i] = current_ds_bounds_upper[j]\n",
    "        store_ss_elcon[j][:, i] = estimated_tde_rates_ss\n",
    "        store_ds_elcon[j][:, i] = estimated_tde_rates_ds\n",
    "        store_ss_kinematic[j][:, i] = kinematic_tde_rates_ss\n",
    "        store_ds_kinematic[j][:, i] = kinematic_tde_rates_ds\n",
    "\n",
    "    # Store new number of OOB elements permesh\n",
    "    n_oob_vec = np.hstack((n_oob_vec, current_noob))\n",
    "\n",
    "    # QP solve with updated TDE slip rate constraints\n",
    "    solution_qp = celeri.lsqlin_qp(\n",
    "        operators.eigen * np.sqrt(weighting_vector_eigen[:, None]),\n",
    "        data_vector_eigen * np.sqrt(weighting_vector_eigen),\n",
    "        0,\n",
    "        qp_inequality_constraints_matrix,  # Inequality matrix\n",
    "        updated_qp_inequality_constraints_data_vector,  # Inequality data vector\n",
    "        None,\n",
    "        None,\n",
    "        None,\n",
    "        None,\n",
    "        None,\n",
    "        {\"show_progress\": False},\n",
    "    )\n",
    "\n",
    "    if solution_qp[\"status\"] != \"optimal\":\n",
    "        logger.error(f\" \")\n",
    "        logger.error(f\"NON OPTIMAL SOLUTION AT: {i=}\")\n",
    "        logger.error(f\" \")\n",
    "        sys.exit()\n",
    "\n",
    "    # Create estimation data structure and calculate derived quantities\n",
    "    estimation_qp.state_vector = np.array(solution_qp[\"x\"]).flatten()\n",
    "    estimation_qp.operator = operators.eigen\n",
    "    celeri.post_process_estimation_eigen(estimation_qp, operators, station, index)\n",
    "\n",
    "    # Calculate total percentage of OOB elements to determine if we iterate again\n",
    "    total_oob = np.sum(n_oob_vec[:, i], axis=0)\n",
    "    total_percentages.append(total_oob / (2 * tde_total) * 100)\n",
    "    total_percentage_satisfied = 100 - total_percentages[-1]\n",
    "    logger.info(\n",
    "        f\"Iteration: {i}, Total %TDE inside coupling bounds: {100-total_percentages[-1]:0.3f}\"\n",
    "    )\n",
    "    print(\" \")\n",
    "\n",
    "    # Decide if iteration should continue\n",
    "    if i <= command.coupling_bounds_max_iter:\n",
    "        if (\n",
    "            total_percentage_satisfied\n",
    "            <= command.coupling_bounds_total_percentage_satisfied_target\n",
    "        ):\n",
    "            continue_iterating = True\n",
    "            i += 1\n",
    "        else:\n",
    "            continue_iterating = False\n",
    "    else:\n",
    "        continue_iterating = False\n",
    "    n_iter = np.copy(i)\n",
    "\n",
    "# Write output\n",
    "celeri.write_output(command, estimation_qp, station, segment, block, meshes)\n",
    "\n",
    "# Delete columns less that n_iter\n",
    "for j in range(n_segment_meshes):\n",
    "    store_ss_lower[j] = store_ss_lower[j][:, 0:n_iter]\n",
    "    store_ss_upper[j] = store_ss_upper[j][:, 0:n_iter]\n",
    "    store_ds_lower[j] = store_ds_lower[j][:, 0:n_iter]\n",
    "    store_ds_upper[j] = store_ds_upper[j][:, 0:n_iter]\n",
    "    store_ss_elcon[j] = store_ss_elcon[j][:, 0:n_iter]\n",
    "    store_ds_elcon[j] = store_ds_elcon[j][:, 0:n_iter]\n",
    "    store_ss_kinematic[j] = store_ss_kinematic[j][:, 0:n_iter]\n",
    "    store_ds_kinematic[j] = store_ds_kinematic[j][:, 0:n_iter]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot convergence with iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_iterative_convergence(mesh_names, meshes, n_oob_vec, n_iter):\n",
    "    # Calculate total mesh elements\n",
    "    tde_total = 0\n",
    "    for i in range(3):\n",
    "        tde_total += meshes[i].n_tde\n",
    "\n",
    "    total_oob = np.sum(n_oob_vec, axis=0)\n",
    "    total_percentages = total_oob / (2 * tde_total) * 100\n",
    "    idx = np.arange(len(total_percentages))\n",
    "\n",
    "    # Plot convergence\n",
    "    plt.figure(figsize=(4, 3))\n",
    "    label_string = f\"total ({total_percentages[n_iter]:0.2f}%)\"\n",
    "    plt.fill_between(idx, total_percentages, color=\"lightgray\", label=label_string)\n",
    "    for i in range(len(mesh_names)):\n",
    "        percentages = n_oob_vec[i, :] / (2 * meshes[i].n_tde) * 100\n",
    "        label_string = f\"{mesh_names[i]} ({percentages[n_iter]:0.2f}%)\"\n",
    "        plt.plot(idx, percentages, linewidth=1.0, label=label_string)\n",
    "\n",
    "    plt.xlabel(\"iteration\")\n",
    "    plt.ylabel(\"% OOB\")\n",
    "    plt.xlim([0, n_iter - 1])\n",
    "    plt.ylim([0, 100])\n",
    "    plt.xticks([0, n_iter - 1])\n",
    "    plt.yticks([0, 100])\n",
    "    legend_handle = plt.legend(\n",
    "        fancybox=False, framealpha=1, facecolor=\"white\", edgecolor=\"black\"\n",
    "    )\n",
    "    legend_handle.get_frame().set_linewidth(0.5)\n",
    "    plt.show()\n",
    "\n",
    "    # Plot convergence\n",
    "    plt.figure(figsize=(4, 3))\n",
    "    label_string = f\"total ({100 - total_percentages[n_iter]:0.2f}%)\"\n",
    "    plt.fill_between(\n",
    "        idx, 100 - total_percentages, color=\"lightgray\", label=label_string\n",
    "    )\n",
    "    for i in range(len(mesh_names)):\n",
    "        percentages = 100 - n_oob_vec[i, :] / (2 * meshes[i].n_tde) * 100\n",
    "        label_string = f\"{mesh_names[i]} ({percentages[n_iter]:0.2f}%)\"\n",
    "        plt.plot(idx, percentages, linewidth=1.0, label=label_string)\n",
    "\n",
    "    plt.xlabel(\"iteration\")\n",
    "    plt.ylabel(\"% IB\")\n",
    "    plt.xlim([0, n_iter - 1])\n",
    "    plt.ylim([0, 100])\n",
    "    plt.xticks([0, n_iter - 1])\n",
    "    plt.yticks([0, 100])\n",
    "    legend_handle = plt.legend(\n",
    "        fancybox=False, framealpha=1, facecolor=\"white\", edgecolor=\"black\"\n",
    "    )\n",
    "    legend_handle.get_frame().set_linewidth(0.5)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "plot_iterative_convergence(\n",
    "    [\"Nankai\", \"Japan\", \"Sagami\"], meshes, n_oob_vec, n_iter=n_iter\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot complete model result after coupling iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "celeri.plot_estimation_summary(\n",
    "    command,\n",
    "    segment,\n",
    "    station,\n",
    "    meshes,\n",
    "    estimation_qp,\n",
    "    lon_range=command.lon_range,\n",
    "    lat_range=command.lat_range,\n",
    "    quiver_scale=command.quiver_scale,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_common_elements():\n",
    "    plt.xlim([-90, 90])\n",
    "    plt.ylim([-90, 90])\n",
    "    plt.xticks([-90, 0, 90])\n",
    "    plt.yticks([-90, 0, 90])\n",
    "    plt.gca().set_aspect(\"equal\")\n",
    "\n",
    "\n",
    "def plot_evolution(field1, field2, mesh_idx):\n",
    "    LINE_COLOR = \"lightgray\"\n",
    "    for i in range(meshes[mesh_idx].n_tde):\n",
    "        plt.plot(\n",
    "            field1[i, :],\n",
    "            field2[i, :],\n",
    "            \"-\",\n",
    "            linewidth=0.1,\n",
    "            color=LINE_COLOR,\n",
    "            zorder=1,\n",
    "        )\n",
    "    plt.plot(field1[:, -1], field2[:, -1], \".k\", markersize=0.5)\n",
    "\n",
    "\n",
    "def plot_coupling_evolution(mesh_idx):\n",
    "    def plot_background():\n",
    "        REGULARIZATION_RATE = 1.0\n",
    "        levels = 101\n",
    "        j_cutoff = 50.0\n",
    "        j = np.linspace(-100, 100, 1000)\n",
    "        b = np.linspace(-100, 100, 1000)\n",
    "        j_grid, b_grid = np.meshgrid(j, b)\n",
    "        j_grid_orig = np.copy(j_grid)\n",
    "        b_grid_orig = np.copy(b_grid)\n",
    "        coupling, _ = get_coupling(\n",
    "            0,\n",
    "            0,\n",
    "            b_grid.flatten(),\n",
    "            j_grid.flatten(),\n",
    "            smoothing_length_scale=0.0,\n",
    "            kinematic_slip_regularization_scale=REGULARIZATION_RATE,\n",
    "        )\n",
    "        coupling_grid = np.reshape(coupling, (1000, 1000))\n",
    "        coupling_grid[coupling_grid > 1.0] = np.nan\n",
    "        coupling_grid[coupling_grid < 0.0] = np.nan\n",
    "\n",
    "        # Create half colormap\n",
    "        # Retrieve a colorcet colormap\n",
    "        # full_cmap = cc.cm[\"coolwarm_r\"]  # Replace with your desired colormap\n",
    "        # full_cmap = cc.cm[\"CET_D8_r\"]  # Replace with your desired colormap\n",
    "        # full_cmap = cc.cm[\"cwr_r\"]  # Replace with your desired colormap\n",
    "        full_cmap = cc.cm[\"bmy_r\"]  # Replace with your desired colormap\n",
    "\n",
    "        # Extract half of the colormap\n",
    "        n_colors = full_cmap.N  # Total number of colors in the colormap\n",
    "        half_cmap = LinearSegmentedColormap.from_list(\n",
    "            \"half_cmap\", full_cmap(np.linspace(0, 0.5, n_colors // 2))\n",
    "        )\n",
    "        # cmap = half_cmap.reversed()\n",
    "        cmap = half_cmap\n",
    "\n",
    "        ch = plt.contourf(\n",
    "            j_grid_orig, b_grid_orig, coupling_grid, cmap=cmap, levels=levels\n",
    "        )\n",
    "        return ch\n",
    "\n",
    "    plt.figure(figsize=(10, 10))\n",
    "\n",
    "    plt.subplot(2, 2, 1)\n",
    "    ch = plot_background()\n",
    "    plot_evolution(store_ss_kinematic[mesh_idx], store_ss_elcon[mesh_idx], mesh_idx)\n",
    "    plot_common_elements()\n",
    "    plt.xlabel(\"$v$ strike-slip kinematic (mm/yr)\")\n",
    "    plt.ylabel(\"$v$ strike-slip elastic (mm/yr)\")\n",
    "    cax = inset_axes(\n",
    "        plt.gca(),\n",
    "        width=\"20%\",\n",
    "        height=\"30%\",\n",
    "        loc=\"upper right\",\n",
    "        bbox_to_anchor=(0.0, 0.0, 0.07, 0.95),  # Position in axes fraction\n",
    "        bbox_transform=plt.gca().transAxes,\n",
    "        borderpad=0,\n",
    "    )\n",
    "    cbar = plt.colorbar(ch, cax=cax, ticks=[0.0, 1.0], label=\"coupling\")\n",
    "\n",
    "    plt.subplot(2, 2, 2)\n",
    "    ch = plot_background()\n",
    "    plot_evolution(store_ss_kinematic[mesh_idx], store_ss_lower[mesh_idx], mesh_idx)\n",
    "    plot_evolution(store_ss_kinematic[mesh_idx], store_ss_upper[mesh_idx], mesh_idx)\n",
    "    plot_common_elements()\n",
    "    plt.xlabel(\"$v$ strike-slip kinematic (mm/yr)\")\n",
    "    plt.ylabel(\"$v$ strike-slip bounds (mm/yr)\")\n",
    "    cax = inset_axes(\n",
    "        plt.gca(),\n",
    "        width=\"20%\",\n",
    "        height=\"30%\",\n",
    "        loc=\"upper right\",\n",
    "        bbox_to_anchor=(0.0, 0.0, 0.07, 0.95),  # Position in axes fraction\n",
    "        bbox_transform=plt.gca().transAxes,\n",
    "        borderpad=0,\n",
    "    )\n",
    "    cbar = plt.colorbar(ch, cax=cax, ticks=[0.0, 1.0], label=\"coupling\")\n",
    "\n",
    "    plt.subplot(2, 2, 3)\n",
    "    ch = plot_background()\n",
    "    plot_evolution(store_ds_kinematic[mesh_idx], store_ds_elcon[mesh_idx], mesh_idx)\n",
    "    plot_common_elements()\n",
    "    plt.xlabel(\"$v$ dip-slip kinematic (mm/yr)\")\n",
    "    plt.ylabel(\"$v$ dip-slip elastic (mm/yr)\")\n",
    "    cax = inset_axes(\n",
    "        plt.gca(),\n",
    "        width=\"20%\",\n",
    "        height=\"30%\",\n",
    "        loc=\"upper right\",\n",
    "        bbox_to_anchor=(0.0, 0.0, 0.07, 0.95),  # Position in axes fraction\n",
    "        bbox_transform=plt.gca().transAxes,\n",
    "        borderpad=0,\n",
    "    )\n",
    "    cbar = plt.colorbar(ch, cax=cax, ticks=[0.0, 1.0], label=\"coupling\")\n",
    "\n",
    "    plt.subplot(2, 2, 4)\n",
    "    ch = plot_background()\n",
    "    plot_evolution(store_ds_kinematic[mesh_idx], store_ds_lower[mesh_idx], mesh_idx)\n",
    "    plot_evolution(store_ds_kinematic[mesh_idx], store_ds_upper[mesh_idx], mesh_idx)\n",
    "    plot_common_elements()\n",
    "    plt.xlabel(\"$v$ dip-slip kinematic (mm/yr)\")\n",
    "    plt.ylabel(\"$v$ dip-slip bounds (mm/yr)\")\n",
    "    cax = inset_axes(\n",
    "        plt.gca(),\n",
    "        width=\"20%\",\n",
    "        height=\"30%\",\n",
    "        loc=\"upper right\",\n",
    "        bbox_to_anchor=(0.0, 0.0, 0.07, 0.95),  # Position in axes fraction\n",
    "        bbox_transform=plt.gca().transAxes,\n",
    "        borderpad=0,\n",
    "    )\n",
    "    cbar = plt.colorbar(ch, cax=cax, ticks=[0.0, 1.0], label=\"coupling\")\n",
    "    plt.suptitle(f\"{meshes[mesh_idx].file_name}\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "for i in range(n_segment_meshes):\n",
    "    plot_coupling_evolution(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot final slip rates and coupling distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quick_plot_coupling(mesh_idx, operators, estimation_qp):\n",
    "    # Multiply rotation vector components by TDE slip rate partials\n",
    "    kinematic = (\n",
    "        operators.rotation_to_tri_slip_rate[mesh_idx]\n",
    "        @ estimation_qp.state_vector[0 : 3 * len(block)]\n",
    "    )\n",
    "\n",
    "    elastic = (\n",
    "        operators.eigenvectors_to_tde_slip[mesh_idx]\n",
    "        @ estimation_qp.state_vector[\n",
    "            index.start_col_eigen[mesh_idx] : index.end_col_eigen[mesh_idx]\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # Calculate final coupling and smoothed kinematic\n",
    "    tde_coupling_ss, kinematic_tde_rates_ss_smooth = get_coupling(\n",
    "        meshes[mesh_idx].lon_centroid,\n",
    "        meshes[mesh_idx].lat_centroid,\n",
    "        elastic[0::2],\n",
    "        kinematic[0::2],\n",
    "        smoothing_length_scale=meshes[\n",
    "            mesh_idx\n",
    "        ].iterative_coupling_smoothing_length_scale,\n",
    "        kinematic_slip_regularization_scale=meshes[\n",
    "            mesh_idx\n",
    "        ].iterative_coupling_kinematic_slip_regularization_scale,\n",
    "    )\n",
    "\n",
    "    tde_coupling_ds, kinematic_tde_rates_ds_smooth = get_coupling(\n",
    "        meshes[mesh_idx].lon_centroid,\n",
    "        meshes[mesh_idx].lat_centroid,\n",
    "        elastic[1::2],\n",
    "        kinematic[1::2],\n",
    "        smoothing_length_scale=meshes[\n",
    "            mesh_idx\n",
    "        ].iterative_coupling_smoothing_length_scale,\n",
    "        kinematic_slip_regularization_scale=meshes[\n",
    "            mesh_idx\n",
    "        ].iterative_coupling_kinematic_slip_regularization_scale,\n",
    "    )\n",
    "\n",
    "    # Strike-slip\n",
    "    plt.figure(figsize=(15, 2))\n",
    "    plt.subplot(1, 4, 1)\n",
    "    plot_mesh(meshes[mesh_idx], kinematic[0::2], plt.gca())\n",
    "    plt.title(\"ss kinematic\")\n",
    "\n",
    "    plt.subplot(1, 4, 2)\n",
    "    plot_mesh(meshes[mesh_idx], kinematic_tde_rates_ss_smooth, plt.gca())\n",
    "    plt.title(\"ss kinematic (smooth)\")\n",
    "\n",
    "    plt.subplot(1, 4, 3)\n",
    "    plot_mesh(meshes[mesh_idx], elastic[0::2], plt.gca())\n",
    "    plt.title(\"ss elastic\")\n",
    "\n",
    "    plt.subplot(1, 4, 4)\n",
    "    plot_mesh(meshes[mesh_idx], tde_coupling_ss, plt.gca())\n",
    "    plt.title(\"ss coupling\")\n",
    "\n",
    "    # Dip-slip\n",
    "    plt.figure(figsize=(15, 2))\n",
    "    plt.subplot(1, 4, 1)\n",
    "    plot_mesh(meshes[mesh_idx], kinematic[1::2], plt.gca())\n",
    "    plt.title(\"ds kinematic\")\n",
    "\n",
    "    plt.subplot(1, 4, 2)\n",
    "    plot_mesh(meshes[mesh_idx], kinematic_tde_rates_ds_smooth, plt.gca())\n",
    "    plt.title(\"ds kinematic (smooth)\")\n",
    "\n",
    "    plt.subplot(1, 4, 3)\n",
    "    plot_mesh(meshes[mesh_idx], elastic[1::2], plt.gca())\n",
    "    plt.title(\"ds elastic\")\n",
    "\n",
    "    plt.subplot(1, 4, 4)\n",
    "    plot_mesh(meshes[mesh_idx], tde_coupling_ds, plt.gca())\n",
    "    plt.title(\"ds coupling\")\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "for i in range(n_segment_meshes):\n",
    "    quick_plot_coupling(i, operators, estimation_qp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fancy visualization.  Hacky but customizable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import warnings\n",
    "from scipy.interpolate import RBFInterpolator\n",
    "from matplotlib import path\n",
    "import scipy.io as sio\n",
    "import pandas as pd\n",
    "\n",
    "MAX_VEL = 60\n",
    "\n",
    "n_grid_x = 500\n",
    "n_grid_y = 500\n",
    "\n",
    "\n",
    "def inpolygon(xq, yq, xv, yv):\n",
    "    shape = xq.shape\n",
    "    xq = xq.reshape(-1)\n",
    "    yq = yq.reshape(-1)\n",
    "    xv = xv.reshape(-1)\n",
    "    yv = yv.reshape(-1)\n",
    "    q = [(xq[i], yq[i]) for i in range(xq.shape[0])]\n",
    "    p = path.Path([(xv[i], yv[i]) for i in range(xv.shape[0])])\n",
    "    return p.contains_points(q).reshape(shape)\n",
    "\n",
    "\n",
    "def rbf_interpolate():\n",
    "    # Observation coordinates and data\n",
    "    # x_vec = np.linspace(231, 239, n_grid_x)\n",
    "    # y_vec = np.linspace(38, 52, n_grid_y)\n",
    "    x_vec = np.linspace(130, 140, n_grid_x)\n",
    "    y_vec = np.linspace(30, 37, n_grid_y)\n",
    "    x_mat, y_mat = np.meshgrid(x_vec, y_vec)\n",
    "    y_mat = y_mat\n",
    "    centroids_lon = meshes[0].centroids[:, 0]\n",
    "    centroids_lat = meshes[0].centroids[:, 1]\n",
    "    centroids_val = fill_value\n",
    "\n",
    "    # Package for RBFInterpolator\n",
    "    xgrid = np.stack((x_mat, y_mat))\n",
    "    xflat = xgrid.reshape(2, -1).T\n",
    "    xobs = np.vstack((centroids_lon, centroids_lat)).T\n",
    "    yobs = centroids_val\n",
    "    yflat = RBFInterpolator(xobs, yobs, kernel=\"cubic\", smoothing=0.01, epsilon=1.5)(\n",
    "        xflat\n",
    "    )\n",
    "    ygrid = yflat.reshape(n_grid_x, n_grid_y)\n",
    "    return xgrid, ygrid\n",
    "\n",
    "\n",
    "def common_plot_elements(segment, lon_range, lat_range):\n",
    "    \"\"\"Elements common to all subplots\n",
    "    Args:\n",
    "        segment (pd.DataFrame): Fault segments\n",
    "        lon_range (Tuple): Longitude range (min, max)\n",
    "        lat_range (Tuple): Latitude range (min, max)\n",
    "    \"\"\"\n",
    "    WORLD_BOUNDARIES = sio.loadmat(\"WorldHiVectors.mat\")\n",
    "    plt.plot(\n",
    "        WORLD_BOUNDARIES[\"lon\"],\n",
    "        WORLD_BOUNDARIES[\"lat\"],\n",
    "        color=\"gray\",\n",
    "        linewidth=0.25,\n",
    "    )\n",
    "    plt.xlim([lon_range[0], lon_range[1]])\n",
    "    plt.ylim([lat_range[0], lat_range[1]])\n",
    "    plt.xticks([lon_range[0], lon_range[1]])\n",
    "    plt.yticks([lat_range[0], lat_range[1]])\n",
    "    plt.gca().set_aspect(\"equal\", adjustable=\"box\")\n",
    "\n",
    "\n",
    "lon_range = [130, 139]\n",
    "lat_range = [30, 37]\n",
    "quiver_scale = 0.5 * command.quiver_scale\n",
    "\n",
    "mesh_idx = 0\n",
    "\n",
    "kinematic = (\n",
    "    operators.rotation_to_tri_slip_rate[mesh_idx]\n",
    "    @ estimation_qp.state_vector[0 : 3 * len(block)]\n",
    ")\n",
    "\n",
    "elastic = (\n",
    "    operators.eigenvectors_to_tde_slip[mesh_idx]\n",
    "    @ estimation_qp.state_vector[\n",
    "        index.start_col_eigen[mesh_idx] : index.end_col_eigen[mesh_idx]\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Calculate final coupling and smoothed kinematic\n",
    "tde_coupling_ss, kinematic_tde_rates_ss_smooth = get_coupling(\n",
    "    meshes[mesh_idx].lon_centroid,\n",
    "    meshes[mesh_idx].lat_centroid,\n",
    "    elastic[0::2],\n",
    "    kinematic[0::2],\n",
    "    smoothing_length_scale=meshes[mesh_idx].iterative_coupling_smoothing_length_scale,\n",
    "    kinematic_slip_regularization_scale=meshes[\n",
    "        mesh_idx\n",
    "    ].iterative_coupling_kinematic_slip_regularization_scale,\n",
    ")\n",
    "\n",
    "tde_coupling_ds, kinematic_tde_rates_ds_smooth = get_coupling(\n",
    "    meshes[mesh_idx].lon_centroid,\n",
    "    meshes[mesh_idx].lat_centroid,\n",
    "    elastic[1::2],\n",
    "    kinematic[1::2],\n",
    "    smoothing_length_scale=meshes[mesh_idx].iterative_coupling_smoothing_length_scale,\n",
    "    kinematic_slip_regularization_scale=meshes[\n",
    "        mesh_idx\n",
    "    ].iterative_coupling_kinematic_slip_regularization_scale,\n",
    ")\n",
    "\n",
    "\n",
    "plt.figure(figsize=(15, 7))\n",
    "\n",
    "# Raw kinematic rates\n",
    "plt.subplot(2, 4, 1)\n",
    "fill_value = kinematic[0::2]\n",
    "xgrid, ygrid = rbf_interpolate()\n",
    "xflat = xgrid.reshape(2, -1).T\n",
    "inpolygon_vals = inpolygon(\n",
    "    xflat[:, 0], xflat[:, 1], meshes[0].x_perimeter, meshes[0].y_perimeter\n",
    ")\n",
    "inpolygon_vals = np.reshape(inpolygon_vals, (n_grid_x, n_grid_y))\n",
    "ygrid[~inpolygon_vals] = np.nan\n",
    "levels = np.linspace(-MAX_VEL, MAX_VEL, 11)\n",
    "common_plot_elements(segment, lon_range, lat_range)\n",
    "ch = plt.contourf(*xgrid, ygrid, cmap=\"Spectral_r\", levels=levels, extend=\"both\")\n",
    "plt.contour(\n",
    "    *xgrid, ygrid, colors=\"k\", linestyles=\"solid\", linewidths=0.25, levels=levels\n",
    ")\n",
    "plt.plot(meshes[0].x_perimeter, meshes[0].y_perimeter, \"-k\", linewidth=1.0)\n",
    "plt.gca().set_aspect(\"equal\", adjustable=\"box\")\n",
    "plt.title(\"a) strike-slip kinematic\", fontsize=10)\n",
    "cax = inset_axes(\n",
    "    plt.gca(),\n",
    "    width=\"20%\",\n",
    "    height=\"30%\",\n",
    "    # loc=\"upper right\",\n",
    "    loc=\"lower left\",\n",
    "    bbox_to_anchor=(0.70, 0.05, 0.10, 0.95),  # Position in axes fraction\n",
    "    bbox_transform=plt.gca().transAxes,\n",
    "    borderpad=0,\n",
    ")\n",
    "cbar = plt.colorbar(ch, cax=cax, ticks=[-MAX_VEL, 0, MAX_VEL], label=\"v (mm/yr)\")\n",
    "\n",
    "# Smoothed kinematic rates\n",
    "plt.subplot(2, 4, 2)\n",
    "fill_value = kinematic_tde_rates_ss_smooth\n",
    "xgrid, ygrid = rbf_interpolate()\n",
    "xflat = xgrid.reshape(2, -1).T\n",
    "inpolygon_vals = inpolygon(\n",
    "    xflat[:, 0], xflat[:, 1], meshes[0].x_perimeter, meshes[0].y_perimeter\n",
    ")\n",
    "inpolygon_vals = np.reshape(inpolygon_vals, (n_grid_x, n_grid_y))\n",
    "ygrid[~inpolygon_vals] = np.nan\n",
    "levels = np.linspace(-MAX_VEL, MAX_VEL, 11)\n",
    "common_plot_elements(segment, lon_range, lat_range)\n",
    "ch = plt.contourf(*xgrid, ygrid, cmap=\"Spectral_r\", levels=levels, extend=\"both\")\n",
    "plt.contour(\n",
    "    *xgrid, ygrid, colors=\"k\", linestyles=\"solid\", linewidths=0.25, levels=levels\n",
    ")\n",
    "plt.plot(meshes[0].x_perimeter, meshes[0].y_perimeter, \"-k\", linewidth=1.0)\n",
    "plt.gca().set_aspect(\"equal\", adjustable=\"box\")\n",
    "plt.title(\"b) strike-slip kinematic (smooth)\", fontsize=10)\n",
    "cax = inset_axes(\n",
    "    plt.gca(),\n",
    "    width=\"20%\",\n",
    "    height=\"30%\",\n",
    "    # loc=\"upper right\",\n",
    "    loc=\"lower left\",\n",
    "    bbox_to_anchor=(0.70, 0.05, 0.10, 0.95),  # Position in axes fraction\n",
    "    bbox_transform=plt.gca().transAxes,\n",
    "    borderpad=0,\n",
    ")\n",
    "cbar = plt.colorbar(ch, cax=cax, ticks=[-MAX_VEL, 0, MAX_VEL], label=\"v (mm/yr)\")\n",
    "\n",
    "# Estimated dip-slip rates\n",
    "plt.subplot(2, 4, 3)\n",
    "fill_value = estimation_qp.tde_strike_slip_rates[0 : meshes[0].n_tde]\n",
    "xgrid, ygrid = rbf_interpolate()\n",
    "xflat = xgrid.reshape(2, -1).T\n",
    "inpolygon_vals = inpolygon(\n",
    "    xflat[:, 0], xflat[:, 1], meshes[0].x_perimeter, meshes[0].y_perimeter\n",
    ")\n",
    "inpolygon_vals = np.reshape(inpolygon_vals, (n_grid_x, n_grid_y))\n",
    "ygrid[~inpolygon_vals] = np.nan\n",
    "levels = np.linspace(-MAX_VEL, MAX_VEL, 11)\n",
    "common_plot_elements(segment, lon_range, lat_range)\n",
    "ch = plt.contourf(*xgrid, ygrid, cmap=\"Spectral_r\", levels=levels, extend=\"both\")\n",
    "plt.contour(\n",
    "    *xgrid, ygrid, colors=\"k\", linestyles=\"solid\", linewidths=0.25, levels=levels\n",
    ")\n",
    "plt.plot(meshes[0].x_perimeter, meshes[0].y_perimeter, \"-k\", linewidth=1.0)\n",
    "plt.gca().set_aspect(\"equal\", adjustable=\"box\")\n",
    "plt.title(\"c) strike-slip elastic\", fontsize=10)\n",
    "cax = inset_axes(\n",
    "    plt.gca(),\n",
    "    width=\"20%\",\n",
    "    height=\"30%\",\n",
    "    # loc=\"upper right\",\n",
    "    loc=\"lower left\",\n",
    "    bbox_to_anchor=(0.70, 0.05, 0.10, 0.95),  # Position in axes fraction\n",
    "    bbox_transform=plt.gca().transAxes,\n",
    "    borderpad=0,\n",
    ")\n",
    "cbar = plt.colorbar(ch, cax=cax, ticks=[-MAX_VEL, 0, MAX_VEL], label=\"v (mm/yr)\")\n",
    "\n",
    "# Coupling\n",
    "plt.subplot(2, 4, 4)\n",
    "fill_value = tde_coupling_ss\n",
    "xgrid, ygrid = rbf_interpolate()\n",
    "xflat = xgrid.reshape(2, -1).T\n",
    "inpolygon_vals = inpolygon(\n",
    "    xflat[:, 0], xflat[:, 1], meshes[0].x_perimeter, meshes[0].y_perimeter\n",
    ")\n",
    "inpolygon_vals = np.reshape(inpolygon_vals, (n_grid_x, n_grid_y))\n",
    "ygrid[~inpolygon_vals] = np.nan\n",
    "levels = np.linspace(0, 1.0, 11)\n",
    "common_plot_elements(segment, lon_range, lat_range)\n",
    "ch = plt.contourf(*xgrid, ygrid, cmap=\"Greys\", levels=levels, extend=\"both\")\n",
    "plt.contour(\n",
    "    *xgrid, ygrid, colors=\"k\", linestyles=\"solid\", linewidths=0.25, levels=levels\n",
    ")\n",
    "plt.plot(meshes[0].x_perimeter, meshes[0].y_perimeter, \"-k\", linewidth=1.0)\n",
    "plt.gca().set_aspect(\"equal\", adjustable=\"box\")\n",
    "plt.title(\"d) strike-slip coupling\", fontsize=10)\n",
    "cax = inset_axes(\n",
    "    plt.gca(),\n",
    "    width=\"20%\",\n",
    "    height=\"30%\",\n",
    "    # loc=\"upper right\",\n",
    "    loc=\"lower left\",\n",
    "    bbox_to_anchor=(0.70, 0.05, 0.10, 0.95),  # Position in axes fraction\n",
    "    bbox_transform=plt.gca().transAxes,\n",
    "    borderpad=0,\n",
    ")\n",
    "cbar = plt.colorbar(ch, cax=cax, ticks=[0, 1], label=\"coupling\")\n",
    "\n",
    "\n",
    "# Raw kinematic rates\n",
    "plt.subplot(2, 4, 5)\n",
    "fill_value = kinematic[1::2]\n",
    "xgrid, ygrid = rbf_interpolate()\n",
    "xflat = xgrid.reshape(2, -1).T\n",
    "inpolygon_vals = inpolygon(\n",
    "    xflat[:, 0], xflat[:, 1], meshes[0].x_perimeter, meshes[0].y_perimeter\n",
    ")\n",
    "inpolygon_vals = np.reshape(inpolygon_vals, (n_grid_x, n_grid_y))\n",
    "ygrid[~inpolygon_vals] = np.nan\n",
    "levels = np.linspace(-MAX_VEL, MAX_VEL, 11)\n",
    "common_plot_elements(segment, lon_range, lat_range)\n",
    "ch = plt.contourf(*xgrid, ygrid, cmap=\"Spectral_r\", levels=levels, extend=\"both\")\n",
    "plt.contour(\n",
    "    *xgrid, ygrid, colors=\"k\", linestyles=\"solid\", linewidths=0.25, levels=levels\n",
    ")\n",
    "plt.plot(meshes[0].x_perimeter, meshes[0].y_perimeter, \"-k\", linewidth=1.0)\n",
    "plt.gca().set_aspect(\"equal\", adjustable=\"box\")\n",
    "plt.title(\"e) dip-slip kinematic\", fontsize=10)\n",
    "cax = inset_axes(\n",
    "    plt.gca(),\n",
    "    width=\"20%\",\n",
    "    height=\"30%\",\n",
    "    # loc=\"upper right\",\n",
    "    loc=\"lower left\",\n",
    "    bbox_to_anchor=(0.70, 0.05, 0.10, 0.95),  # Position in axes fraction\n",
    "    bbox_transform=plt.gca().transAxes,\n",
    "    borderpad=0,\n",
    ")\n",
    "cbar = plt.colorbar(ch, cax=cax, ticks=[-MAX_VEL, 0, MAX_VEL], label=\"v (mm/yr)\")\n",
    "\n",
    "# Smoothed kinematic rates\n",
    "plt.subplot(2, 4, 6)\n",
    "fill_value = kinematic_tde_rates_ds_smooth\n",
    "xgrid, ygrid = rbf_interpolate()\n",
    "xflat = xgrid.reshape(2, -1).T\n",
    "inpolygon_vals = inpolygon(\n",
    "    xflat[:, 0], xflat[:, 1], meshes[0].x_perimeter, meshes[0].y_perimeter\n",
    ")\n",
    "inpolygon_vals = np.reshape(inpolygon_vals, (n_grid_x, n_grid_y))\n",
    "ygrid[~inpolygon_vals] = np.nan\n",
    "levels = np.linspace(-MAX_VEL, MAX_VEL, 11)\n",
    "common_plot_elements(segment, lon_range, lat_range)\n",
    "ch = plt.contourf(*xgrid, ygrid, cmap=\"Spectral_r\", levels=levels, extend=\"both\")\n",
    "plt.contour(\n",
    "    *xgrid, ygrid, colors=\"k\", linestyles=\"solid\", linewidths=0.25, levels=levels\n",
    ")\n",
    "plt.plot(meshes[0].x_perimeter, meshes[0].y_perimeter, \"-k\", linewidth=1.0)\n",
    "plt.gca().set_aspect(\"equal\", adjustable=\"box\")\n",
    "plt.title(\"f) dip-slip kinematic (smooth)\", fontsize=10)\n",
    "cax = inset_axes(\n",
    "    plt.gca(),\n",
    "    width=\"20%\",\n",
    "    height=\"30%\",\n",
    "    # loc=\"upper right\",\n",
    "    loc=\"lower left\",\n",
    "    bbox_to_anchor=(0.70, 0.05, 0.10, 0.95),  # Position in axes fraction\n",
    "    bbox_transform=plt.gca().transAxes,\n",
    "    borderpad=0,\n",
    ")\n",
    "cbar = plt.colorbar(ch, cax=cax, ticks=[-MAX_VEL, 0, MAX_VEL], label=\"v (mm/yr)\")\n",
    "\n",
    "# Estimated dip-slip rates\n",
    "plt.subplot(2, 4, 7)\n",
    "fill_value = estimation_qp.tde_dip_slip_rates[0 : meshes[0].n_tde]\n",
    "xgrid, ygrid = rbf_interpolate()\n",
    "xflat = xgrid.reshape(2, -1).T\n",
    "inpolygon_vals = inpolygon(\n",
    "    xflat[:, 0], xflat[:, 1], meshes[0].x_perimeter, meshes[0].y_perimeter\n",
    ")\n",
    "inpolygon_vals = np.reshape(inpolygon_vals, (n_grid_x, n_grid_y))\n",
    "ygrid[~inpolygon_vals] = np.nan\n",
    "levels = np.linspace(-MAX_VEL, MAX_VEL, 11)\n",
    "common_plot_elements(segment, lon_range, lat_range)\n",
    "ch = plt.contourf(*xgrid, ygrid, cmap=\"Spectral_r\", levels=levels, extend=\"both\")\n",
    "plt.contour(\n",
    "    *xgrid, ygrid, colors=\"k\", linestyles=\"solid\", linewidths=0.25, levels=levels\n",
    ")\n",
    "plt.plot(meshes[0].x_perimeter, meshes[0].y_perimeter, \"-k\", linewidth=1.0)\n",
    "plt.gca().set_aspect(\"equal\", adjustable=\"box\")\n",
    "plt.title(\"g) dip-slip elastic\", fontsize=10)\n",
    "cax = inset_axes(\n",
    "    plt.gca(),\n",
    "    width=\"20%\",\n",
    "    height=\"30%\",\n",
    "    # loc=\"upper right\",\n",
    "    loc=\"lower left\",\n",
    "    bbox_to_anchor=(0.70, 0.05, 0.10, 0.95),  # Position in axes fraction\n",
    "    bbox_transform=plt.gca().transAxes,\n",
    "    borderpad=0,\n",
    ")\n",
    "cbar = plt.colorbar(ch, cax=cax, ticks=[-MAX_VEL, 0, MAX_VEL], label=\"v (mm/yr)\")\n",
    "\n",
    "# Coupling\n",
    "plt.subplot(2, 4, 8)\n",
    "fill_value = tde_coupling_ds\n",
    "xgrid, ygrid = rbf_interpolate()\n",
    "xflat = xgrid.reshape(2, -1).T\n",
    "inpolygon_vals = inpolygon(\n",
    "    xflat[:, 0], xflat[:, 1], meshes[0].x_perimeter, meshes[0].y_perimeter\n",
    ")\n",
    "inpolygon_vals = np.reshape(inpolygon_vals, (n_grid_x, n_grid_y))\n",
    "ygrid[~inpolygon_vals] = np.nan\n",
    "levels = np.linspace(0, 1.0, 11)\n",
    "common_plot_elements(segment, lon_range, lat_range)\n",
    "ch = plt.contourf(*xgrid, ygrid, cmap=\"Greys\", levels=levels, extend=\"both\")\n",
    "plt.contour(\n",
    "    *xgrid, ygrid, colors=\"k\", linestyles=\"solid\", linewidths=0.25, levels=levels\n",
    ")\n",
    "plt.plot(meshes[0].x_perimeter, meshes[0].y_perimeter, \"-k\", linewidth=1.0)\n",
    "plt.gca().set_aspect(\"equal\", adjustable=\"box\")\n",
    "plt.title(\"h) dip-slip coupling\", fontsize=10)\n",
    "cax = inset_axes(\n",
    "    plt.gca(),\n",
    "    width=\"20%\",\n",
    "    height=\"30%\",\n",
    "    # loc=\"upper right\",\n",
    "    loc=\"lower left\",\n",
    "    bbox_to_anchor=(0.70, 0.05, 0.10, 0.95),  # Position in axes fraction\n",
    "    bbox_transform=plt.gca().transAxes,\n",
    "    borderpad=0,\n",
    ")\n",
    "cbar = plt.colorbar(ch, cax=cax, ticks=[0, 1], label=\"coupling\")\n",
    "\n",
    "# plt.savefig(\"nankai_kinematic_elastic_coupling.pdf\")\n",
    "# plt.savefig(\"nankai_kinematic_elastic_coupling.png\", dpi=500)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient descent experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = operators.eigen * np.sqrt(weighting_vector_eigen[:, None])\n",
    "b = data_vector_eigen * np.sqrt(weighting_vector_eigen)\n",
    "m, n = A.shape\n",
    "\n",
    "# Column preconditioning\n",
    "column_norms = np.linalg.norm(A, axis=0) + 1e-4  # Avoid division by zero\n",
    "D_inv = 1 / column_norms  # Preconditioning scaling factors\n",
    "A_pre = A * D_inv  # Rescale columns of A\n",
    "b_pre = b  # b remains unchanged\n",
    "\n",
    "# Gradient descent parameters\n",
    "learning_rate = 1e-2\n",
    "num_iterations = 1000\n",
    "x_pre = np.zeros(n)  # Initial guess for preconditioned system\n",
    "\n",
    "# Gradient descent loop\n",
    "for iteration in range(num_iterations):\n",
    "    gradient = A_pre.T @ (A_pre @ x_pre - b_pre)  # Preconditioned gradient\n",
    "    x_pre -= learning_rate * gradient\n",
    "\n",
    "# Recover the unpreconditioned solution\n",
    "x = x_pre * D_inv\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(estimation_qp.state_vector[0:60], \"b+\")\n",
    "plt.plot(x[0:60], \"r.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "estimation_gd = copy.deepcopy(estimation_qp)\n",
    "estimation_gd.state_vector = x\n",
    "celeri.post_process_estimation_eigen(estimation_gd, operators, station, index)\n",
    "\n",
    "celeri.plot_estimation_summary(\n",
    "    command,\n",
    "    segment,\n",
    "    station,\n",
    "    meshes,\n",
    "    estimation_gd,\n",
    "    lon_range=command.lon_range,\n",
    "    lat_range=command.lat_range,\n",
    "    quiver_scale=command.quiver_scale,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse.linalg import cg\n",
    "\n",
    "# Example: Dense matrix A and vector b\n",
    "# np.random.seed(0)\n",
    "# m, n = 100, 50\n",
    "# A = np.random.randn(m, n)\n",
    "# b = np.random.randn(m)\n",
    "\n",
    "A = operators.eigen * np.sqrt(weighting_vector_eigen[:, None])\n",
    "b = data_vector_eigen * np.sqrt(weighting_vector_eigen)\n",
    "m, n = A.shape\n",
    "\n",
    "# Step 1: Compute column norms for preconditioning\n",
    "column_norms = np.linalg.norm(A, axis=0) + 1e-8  # Avoid division by zero\n",
    "D_inv = 1 / column_norms  # Inverse of column norms\n",
    "A_pre = A * D_inv  # Preconditioned matrix\n",
    "b_pre = b  # Right-hand side remains unchanged\n",
    "\n",
    "# Step 2: Solve the preconditioned system using CG\n",
    "# A.T @ A must be symmetric positive-definite for CG\n",
    "AtA_pre = A_pre.T @ A_pre\n",
    "Atb_pre = A_pre.T @ b_pre\n",
    "\n",
    "x_pre, info = cg(AtA_pre, Atb_pre, tol=1e-6, maxiter=1000)\n",
    "\n",
    "# Step 3: Recover the original solution\n",
    "x = x_pre * D_inv\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(estimation_qp.state_vector, \"b+\")\n",
    "plt.plot(x, \"r.\")\n",
    "plt.show()\n",
    "\n",
    "# print(\"Solution x (with column preconditioning):\", x)\n",
    "# print(\"Convergence info:\", info)  # 0 indicates successful convergence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "estimation_cg = copy.deepcopy(estimation_qp)\n",
    "estimation_cg.state_vector = x\n",
    "celeri.post_process_estimation_eigen(estimation_cg, operators, station, index)\n",
    "\n",
    "celeri.plot_estimation_summary(\n",
    "    command,\n",
    "    segment,\n",
    "    station,\n",
    "    meshes,\n",
    "    estimation_cg,\n",
    "    lon_range=command.lon_range,\n",
    "    lat_range=command.lat_range,\n",
    "    quiver_scale=command.quiver_scale,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Count number of OOB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_n_oob_single_mesh(\n",
    "    operators,\n",
    "    index,\n",
    "    meshes,\n",
    "    mesh_idx,\n",
    "    estimation_qp,\n",
    "):\n",
    "    # Get kinematic rates on mesh elements\n",
    "    kinematic_tde_rates = (\n",
    "        operators.rotation_to_tri_slip_rate[mesh_idx]\n",
    "        @ estimation_qp.state_vector[0 : 3 * len(block)]\n",
    "    )\n",
    "\n",
    "    # Get estimated elastic rates on mesh elements\n",
    "    estimated_tde_rates = (\n",
    "        operators.eigenvectors_to_tde_slip[mesh_idx]\n",
    "        @ estimation_qp.state_vector[\n",
    "            index.start_col_eigen[mesh_idx] : index.end_col_eigen[mesh_idx]\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # Calculate strike-slip and dip-slip coupling\n",
    "    tde_coupling_ss, kinematic_tde_rates_ss_smooth = get_coupling(\n",
    "        meshes[mesh_idx].lon_centroid,\n",
    "        meshes[mesh_idx].lat_centroid,\n",
    "        estimated_tde_rates[0::2],\n",
    "        kinematic_tde_rates[0::2],\n",
    "        smoothing_length_scale=meshes[\n",
    "            mesh_idx\n",
    "        ].iterative_coupling_smoothing_length_scale,\n",
    "        kinematic_slip_regularization_scale=meshes[\n",
    "            mesh_idx\n",
    "        ].iterative_coupling_kinematic_slip_regularization_scale,\n",
    "    )\n",
    "\n",
    "    tde_coupling_ds, kinematic_tde_rates_ds_smooth = get_coupling(\n",
    "        meshes[mesh_idx].lon_centroid,\n",
    "        meshes[mesh_idx].lat_centroid,\n",
    "        estimated_tde_rates[1::2],\n",
    "        kinematic_tde_rates[1::2],\n",
    "        smoothing_length_scale=meshes[\n",
    "            mesh_idx\n",
    "        ].iterative_coupling_smoothing_length_scale,\n",
    "        kinematic_slip_regularization_scale=meshes[\n",
    "            mesh_idx\n",
    "        ].iterative_coupling_kinematic_slip_regularization_scale,\n",
    "    )\n",
    "\n",
    "    tde_coupling_ss_lower_oob_idx = np.where(\n",
    "        tde_coupling_ss < meshes[mesh_idx].qp_mesh_tde_slip_rate_lower_bound_ss_coupling\n",
    "    )[0]\n",
    "\n",
    "    tde_coupling_ss_upper_oob_idx = np.where(\n",
    "        tde_coupling_ss > meshes[mesh_idx].qp_mesh_tde_slip_rate_upper_bound_ss_coupling\n",
    "    )[0]\n",
    "\n",
    "    tde_coupling_ds_lower_oob_idx = np.where(\n",
    "        tde_coupling_ds < meshes[mesh_idx].qp_mesh_tde_slip_rate_lower_bound_ds_coupling\n",
    "    )[0]\n",
    "\n",
    "    tde_coupling_ds_upper_oob_idx = np.where(\n",
    "        tde_coupling_ds > meshes[mesh_idx].qp_mesh_tde_slip_rate_upper_bound_ds_coupling\n",
    "    )[0]\n",
    "\n",
    "    n_oob = (\n",
    "        len(tde_coupling_ss_lower_oob_idx)\n",
    "        + len(tde_coupling_ss_upper_oob_idx)\n",
    "        + len(tde_coupling_ds_lower_oob_idx)\n",
    "        + len(tde_coupling_ds_upper_oob_idx)\n",
    "    )\n",
    "    return n_oob\n",
    "\n",
    "\n",
    "def get_n_oob_all_meshes(\n",
    "    operators,\n",
    "    index,\n",
    "    meshes,\n",
    "    estimation_qp,\n",
    "):\n",
    "    n_oob_all_meshes = 0\n",
    "    for i in range(n_segment_meshes):\n",
    "        n_oob = get_n_oob_single_mesh(\n",
    "            operators,\n",
    "            index,\n",
    "            meshes,\n",
    "            i,\n",
    "            estimation_qp,\n",
    "        )\n",
    "        n_oob_all_meshes += n_oob\n",
    "    return n_oob_all_meshes\n",
    "\n",
    "\n",
    "n_oob_all_meshes = get_n_oob_all_meshes(\n",
    "    operators,\n",
    "    index,\n",
    "    meshes,\n",
    "    estimation_qp,\n",
    ")\n",
    "print(n_oob_all_meshes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CG solve with data and coupling loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "# Example: Define an arbitrary loss function\n",
    "def loss_function_pre(x_pre):\n",
    "    # Compute the preconditioned loss\n",
    "    residual = A_pre @ x_pre - b_pre\n",
    "    coupling_loss = 0.0\n",
    "    current_state_vector = x_pre * D_inv\n",
    "    estimation_qp.state_vector = current_state_vector\n",
    "    n_oob_all_meshes = get_n_oob_all_meshes(\n",
    "        operators,\n",
    "        index,\n",
    "        meshes,\n",
    "        estimation_qp,\n",
    "    )\n",
    "    print(f\"{n_oob_all_meshes=}\")\n",
    "    print(f\"{0.5 * np.dot(residual.T, residual)=}\")\n",
    "    coupling_loss = 1e2 * n_oob_all_meshes\n",
    "    return 0.5 * np.dot(residual.T, residual) + coupling_loss\n",
    "\n",
    "\n",
    "def gradient_pre(x_pre):\n",
    "    # Compute the gradient for the preconditioned system\n",
    "    return A_pre.T @ (A_pre @ x_pre - b_pre)\n",
    "\n",
    "\n",
    "# Conjugate Gradient for preconditioned system\n",
    "def conjugate_gradient_preconditioned(L, grad, x0, D_inv, tol=1e-6, max_iter=10):\n",
    "    \"\"\"\n",
    "    Conjugate Gradient for arbitrary loss functions with column preconditioning.\n",
    "    Args:\n",
    "        L: Loss function\n",
    "        grad: Gradient of the loss\n",
    "        x0: Initial guess\n",
    "        D_inv: Inverse of column scaling matrix\n",
    "        tol: Convergence tolerance\n",
    "        max_iter: Maximum iterations\n",
    "    Returns:\n",
    "        x: Original solution vector\n",
    "    \"\"\"\n",
    "    x_pre = x0  # Preconditioned solution\n",
    "    g_pre = grad(x_pre)\n",
    "    p_pre = -g_pre\n",
    "\n",
    "    for k in range(max_iter):\n",
    "        print(f\"{k=}\")\n",
    "        # Line search to find optimal step size\n",
    "        alpha = line_search(L, grad, x_pre, p_pre)\n",
    "        x_pre_new = x_pre + alpha * p_pre\n",
    "\n",
    "        # Check convergence\n",
    "        g_pre_new = grad(x_pre_new)\n",
    "        if np.linalg.norm(g_pre_new) < tol:\n",
    "            print(f\"Converged in {k+1} iterations.\")\n",
    "            return x_pre_new * D_inv  # Rescale back to original solution\n",
    "\n",
    "        # Update direction\n",
    "        beta = np.dot(g_pre_new, g_pre_new) / np.dot(g_pre, g_pre)\n",
    "        p_pre = -g_pre_new + beta * p_pre\n",
    "\n",
    "        # Update variables for next iteration\n",
    "        x_pre, g_pre = x_pre_new, g_pre_new\n",
    "\n",
    "    print(\"Reached maximum iterations.\")\n",
    "    return x_pre * D_inv  # Rescale back to original solution\n",
    "\n",
    "\n",
    "# Example inputs\n",
    "np.random.seed(0)\n",
    "# m, n = 100, 50\n",
    "# A = np.random.randn(m, n)\n",
    "# b = np.random.randn(m)\n",
    "\n",
    "A = operators.eigen * np.sqrt(weighting_vector_eigen[:, None])\n",
    "b = data_vector_eigen * np.sqrt(weighting_vector_eigen)\n",
    "m, n = A.shape\n",
    "\n",
    "\n",
    "# Step 1: Column Preconditioning\n",
    "column_norms = np.linalg.norm(A, axis=0) + 1e-8  # Avoid division by zero\n",
    "D_inv = 1 / column_norms\n",
    "A_pre = A * D_inv  # Preconditioned matrix\n",
    "b_pre = b  # b remains unchanged\n",
    "\n",
    "# Step 2: Initial guess and line search\n",
    "x0 = np.zeros(n)\n",
    "\n",
    "\n",
    "def line_search(L, grad, x, p, alpha_init=1.0, tol=1e-4):\n",
    "    alpha = alpha_init\n",
    "    c = 1e-4\n",
    "    while L(x + alpha * p) > L(x) + c * alpha * np.dot(grad(x), p):\n",
    "        alpha *= 0.5  # Reduce step size\n",
    "        if alpha < 1e-8:\n",
    "            break\n",
    "    return alpha\n",
    "\n",
    "\n",
    "# CG solve\n",
    "x_sol = conjugate_gradient_preconditioned(loss_function_pre, gradient_pre, x0, D_inv)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(estimation_qp.state_vector, \"b+\")\n",
    "plt.plot(x_sol, \"r.\")\n",
    "plt.show()\n",
    "\n",
    "# print(\"Solution x (with column preconditioning):\", x_sol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimation_cg = copy.deepcopy(estimation_qp)\n",
    "estimation_cg.state_vector = x_sol\n",
    "celeri.post_process_estimation_eigen(estimation_cg, operators, station, index)\n",
    "\n",
    "celeri.plot_estimation_summary(\n",
    "    command,\n",
    "    segment,\n",
    "    station,\n",
    "    meshes,\n",
    "    estimation_cg,\n",
    "    lon_range=command.lon_range,\n",
    "    lat_range=command.lat_range,\n",
    "    quiver_scale=command.quiver_scale,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.optimize import minimize\n",
    "from typing import Callable, Tuple, Optional\n",
    "\n",
    "\n",
    "def create_objective_function(\n",
    "    A: np.ndarray,\n",
    "    b: np.ndarray,\n",
    "    f: Callable[[np.ndarray], float],\n",
    "    lambda_reg: float = 1.0,\n",
    ") -> Callable[[np.ndarray], float]:\n",
    "    \"\"\"\n",
    "    Creates the objective function that combines L2 norm of residual with a non-linear term.\n",
    "\n",
    "    Args:\n",
    "        A: Matrix A in the system Ax = b\n",
    "        b: Vector b in the system Ax = b\n",
    "        f: Non-linear function f(x) to be included in the optimization\n",
    "        lambda_reg: Weight for the non-linear term (default: 1.0)\n",
    "\n",
    "    Returns:\n",
    "        Callable that computes the combined objective value\n",
    "    \"\"\"\n",
    "\n",
    "    def objective(x: np.ndarray) -> float:\n",
    "        # Compute L2 norm of residual\n",
    "        residual = A @ x - b\n",
    "        l2_norm = np.sum(residual**2)\n",
    "\n",
    "        # Compute non-linear term\n",
    "        nonlinear_term = f(x)\n",
    "\n",
    "        # Combined objective\n",
    "        return l2_norm + lambda_reg * nonlinear_term\n",
    "\n",
    "    return objective\n",
    "\n",
    "\n",
    "def solve_with_nonlinear_term(\n",
    "    A: np.ndarray,\n",
    "    b: np.ndarray,\n",
    "    f: Callable[[np.ndarray], float],\n",
    "    x0: Optional[np.ndarray] = None,\n",
    "    lambda_reg: float = 1.0,\n",
    "    **kwargs\n",
    ") -> Tuple[np.ndarray, bool]:\n",
    "    \"\"\"\n",
    "    Solves the system Ax = b while including a non-linear term f(x) using conjugate gradient.\n",
    "\n",
    "    Args:\n",
    "        A: Matrix A in the system Ax = b\n",
    "        b: Vector b in the system Ax = b\n",
    "        f: Non-linear function f(x) to be included in the optimization\n",
    "        x0: Initial guess for x (default: random initialization)\n",
    "        lambda_reg: Weight for the non-linear term (default: 1.0)\n",
    "        **kwargs: Additional arguments to pass to scipy.optimize.minimize\n",
    "\n",
    "    Returns:\n",
    "        Tuple of (optimal x, whether optimization succeeded)\n",
    "    \"\"\"\n",
    "    # Check dimensions\n",
    "    n = A.shape[1]\n",
    "    if x0 is None:\n",
    "        x0 = np.random.randn(n)\n",
    "\n",
    "    # Create objective function\n",
    "    objective = create_objective_function(A, b, f, lambda_reg)\n",
    "\n",
    "    # Set default optimization parameters if not provided\n",
    "    default_params = {\"method\": \"CG\", \"options\": {\"maxiter\": 1000, \"gtol\": 1e-6}}\n",
    "\n",
    "    # Update with user-provided parameters\n",
    "    default_params.update(kwargs)\n",
    "\n",
    "    # Solve optimization problem\n",
    "    result = minimize(objective, x0, **default_params)\n",
    "\n",
    "    return result.x, result.success\n",
    "\n",
    "\n",
    "# Example usage\n",
    "def example():\n",
    "    # Generate sample problem\n",
    "    n = 100\n",
    "    m = 80\n",
    "    np.random.seed(42)\n",
    "    A = np.random.randn(m, n)\n",
    "    x_true = np.random.randn(n)\n",
    "    b = A @ x_true + 0.01 * np.random.randn(m)\n",
    "\n",
    "    # Define non-linear term (e.g., L1 regularization)\n",
    "    def f(x: np.ndarray) -> float:\n",
    "        return np.sum(np.abs(x))\n",
    "\n",
    "    # Solve the system\n",
    "    x_opt, success = solve_with_nonlinear_term(A, b, f, lambda_reg=0.1)\n",
    "\n",
    "    if success:\n",
    "        print(\"Optimization succeeded!\")\n",
    "        print(\"L2 error:\", np.linalg.norm(A @ x_opt - b))\n",
    "        print(\"True x vs. recovered x error:\", np.linalg.norm(x_true - x_opt))\n",
    "    else:\n",
    "        print(\"Optimization failed!\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    example()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "\n",
    "def objective(x: np.ndarray, A: np.ndarray, b: np.ndarray) -> float:\n",
    "    \"\"\"\n",
    "    Computes the L2 norm of the residual: ||Ax - b||^2\n",
    "    \"\"\"\n",
    "    residual = A @ x - b\n",
    "    return np.sum(residual**2)\n",
    "\n",
    "\n",
    "# Generate sample problem\n",
    "n = 100  # dimension of x\n",
    "m = 80  # number of equations\n",
    "np.random.seed(42)\n",
    "# A = np.random.randn(m, n)\n",
    "# x_true = np.random.randn(n)\n",
    "# b = A @ x_true + 0.01 * np.random.randn(m)  # add small noise\n",
    "\n",
    "A = operators.eigen * np.sqrt(weighting_vector_eigen[:, None])\n",
    "b = data_vector_eigen * np.sqrt(weighting_vector_eigen)\n",
    "\n",
    "m, n = A.shape\n",
    "\n",
    "\n",
    "# # Step 1: Column Preconditioning\n",
    "# column_norms = np.linalg.norm(A, axis=0) + 1e-8  # Avoid division by zero\n",
    "# D_inv = 1 / column_norms\n",
    "# A_pre = A * D_inv  # Preconditioned matrix\n",
    "# b_pre = b  # b remains unchanged\n",
    "\n",
    "# Initial guess\n",
    "x0 = np.zeros(n)\n",
    "\n",
    "# Solve using conjugate gradient\n",
    "result = minimize(\n",
    "    objective, x0, args=(A, b), method=\"CG\", options={\"maxiter\": 1000, \"gtol\": 1e-6}\n",
    ")\n",
    "\n",
    "# Check results\n",
    "if result.success:\n",
    "    print(\"Optimization succeeded!\")\n",
    "    print(\"L2 error:\", np.linalg.norm(A @ result.x - b))\n",
    "    print(\"True x vs. recovered x error:\", np.linalg.norm(x_true - result.x))\n",
    "else:\n",
    "    print(\"Optimization failed!\")\n",
    "    print(\"Message:\", result.message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(result[\"x\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "\n",
    "def normalize_columns(A: np.ndarray) -> tuple[np.ndarray, np.ndarray]:\n",
    "    \"\"\"\n",
    "    Normalize columns of matrix A and return scaling factors.\n",
    "    Returns the normalized matrix and column norms.\n",
    "    \"\"\"\n",
    "    # Compute column norms\n",
    "    col_norms = np.sqrt(np.sum(A**2, axis=0))\n",
    "\n",
    "    # Avoid division by zero\n",
    "    col_norms[col_norms == 0] = 1.0\n",
    "\n",
    "    # Normalize columns\n",
    "    A_normalized = A / col_norms[None, :]\n",
    "\n",
    "    return A_normalized, col_norms\n",
    "\n",
    "\n",
    "def objective(x_scaled: np.ndarray, A_norm: np.ndarray, b: np.ndarray) -> float:\n",
    "    \"\"\"\n",
    "    Computes the L2 norm of the residual: ||A_norm @ x_scaled - b||^2\n",
    "    \"\"\"\n",
    "    residual = A_norm @ x_scaled - b\n",
    "    return np.sum(residual**2)\n",
    "\n",
    "\n",
    "# Generate sample problem\n",
    "A = operators.eigen * np.sqrt(weighting_vector_eigen[:, None])\n",
    "b = data_vector_eigen * np.sqrt(weighting_vector_eigen)\n",
    "m, n = A.shape\n",
    "\n",
    "# Precondition A with column normalization\n",
    "A_normalized, col_norms = normalize_columns(A)\n",
    "\n",
    "# Initial guess\n",
    "x0_scaled = np.zeros(n)\n",
    "\n",
    "# Solve using conjugate gradient with normalized system\n",
    "result = minimize(\n",
    "    objective,\n",
    "    x0_scaled,\n",
    "    args=(A_normalized, b),\n",
    "    method=\"CG\",\n",
    "    options={\"maxiter\": 10000, \"gtol\": 1e-1},\n",
    ")\n",
    "\n",
    "x_recovered = result.x / col_norms\n",
    "\n",
    "if result.success:\n",
    "    # Unscale the solution\n",
    "    # x_recovered = result.x / col_norms\n",
    "\n",
    "    print(\"Optimization succeeded!\")\n",
    "    print(\"L2 error:\", np.linalg.norm(A @ x_recovered - b))\n",
    "    # print(\"True x vs. recovered x error:\", np.linalg.norm(x_true - x_recovered))\n",
    "    print(\"Condition number of original A:\", np.linalg.cond(A))\n",
    "    print(\"Condition number of normalized A:\", np.linalg.cond(A_normalized))\n",
    "else:\n",
    "    print(\"Optimization failed!\")\n",
    "    print(\"Message:\", result.message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_idx = 0\n",
    "end_idx = 60\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(estimation_qp.state_vector[start_idx:end_idx], \"b+\")\n",
    "plt.plot(x_recovered[start_idx:end_idx], \"r.\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "estimation_gd = copy.deepcopy(estimation_qp)\n",
    "estimation_gd.state_vector = x_recovered\n",
    "celeri.post_process_estimation_eigen(estimation_gd, operators, station, index)\n",
    "\n",
    "celeri.plot_estimation_summary(\n",
    "    command,\n",
    "    segment,\n",
    "    station,\n",
    "    meshes,\n",
    "    estimation_gd,\n",
    "    lon_range=command.lon_range,\n",
    "    lat_range=command.lat_range,\n",
    "    quiver_scale=command.quiver_scale,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(estimation_qp.strike_slip_rates, \"b+\")\n",
    "plt.plot(estimation_gd.strike_slip_rates, \"r.\")\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(estimation_qp.tensile_slip_rates, \"b+\")\n",
    "plt.plot(estimation_gd.tensile_slip_rates, \"r.\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "# Generate sample problem\n",
    "A = operators.eigen * np.sqrt(weighting_vector_eigen[:, None])\n",
    "b = data_vector_eigen * np.sqrt(weighting_vector_eigen)\n",
    "m, n = A.shape\n",
    "\n",
    "# Precondition A with column normalization\n",
    "A_normalized, col_norms = normalize_columns(A)\n",
    "\n",
    "\n",
    "def normalize_columns(A: np.ndarray) -> tuple[np.ndarray, np.ndarray]:\n",
    "    \"\"\"\n",
    "    Normalize columns of matrix A and return scaling factors.\n",
    "    Returns the normalized matrix and column norms.\n",
    "    \"\"\"\n",
    "    # Compute column norms\n",
    "    col_norms = np.sqrt(np.sum(A**2, axis=0))\n",
    "\n",
    "    # Avoid division by zero\n",
    "    col_norms[col_norms == 0] = 1.0\n",
    "\n",
    "    # Normalize columns\n",
    "    A_normalized = A / col_norms[None, :]\n",
    "\n",
    "    return A_normalized, col_norms\n",
    "\n",
    "\n",
    "def objective(x_scaled: np.ndarray, A_norm: np.ndarray, b: np.ndarray) -> float:\n",
    "    \"\"\"\n",
    "    Computes the L2 norm of the residual: ||A_norm @ x_scaled - b||^2\n",
    "    \"\"\"\n",
    "\n",
    "    # print(operators.eigen.shape)\n",
    "    coupling_loss = 0.0\n",
    "    current_state_vector = x_pre * D_inv\n",
    "    estimation_qp.state_vector = x_scaled / col_norms\n",
    "    n_oob_all_meshes = get_n_oob_all_meshes(\n",
    "        operators,\n",
    "        index,\n",
    "        meshes,\n",
    "        estimation_qp,\n",
    "    )\n",
    "    print(f\"{n_oob_all_meshes=}\")\n",
    "    n_oob = 1.0\n",
    "\n",
    "    residual = A_norm @ x_scaled - b + n_oob\n",
    "    return np.sum(residual**2)\n",
    "\n",
    "\n",
    "# # Generate sample problem\n",
    "# A = operators.eigen * np.sqrt(weighting_vector_eigen[:, None])\n",
    "# b = data_vector_eigen * np.sqrt(weighting_vector_eigen)\n",
    "# m, n = A.shape\n",
    "\n",
    "# # Precondition A with column normalization\n",
    "# A_normalized, col_norms = normalize_columns(A)\n",
    "\n",
    "# Initial guess\n",
    "x0_scaled = np.zeros(n)\n",
    "\n",
    "# Solve using conjugate gradient with normalized system\n",
    "result = minimize(\n",
    "    objective,\n",
    "    x0_scaled,\n",
    "    args=(A_normalized, b),\n",
    "    method=\"CG\",\n",
    "    options={\"maxiter\": 10000, \"gtol\": 1e1},\n",
    ")\n",
    "\n",
    "x_recovered = result.x / col_norms\n",
    "\n",
    "if result.success:\n",
    "    # Unscale the solution\n",
    "    # x_recovered = result.x / col_norms\n",
    "\n",
    "    print(\"Optimization succeeded!\")\n",
    "    print(\"L2 error:\", np.linalg.norm(A @ x_recovered - b))\n",
    "    # print(\"True x vs. recovered x error:\", np.linalg.norm(x_true - x_recovered))\n",
    "    print(\"Condition number of original A:\", np.linalg.cond(A))\n",
    "    print(\"Condition number of normalized A:\", np.linalg.cond(A_normalized))\n",
    "else:\n",
    "    print(\"Optimization failed!\")\n",
    "    print(\"Message:\", result.message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimation_minimize = copy.deepcopy(estimation_qp)\n",
    "estimation_minimize.state_vector = x_recovered\n",
    "celeri.post_process_estimation_eigen(estimation_minimize, operators, station, index)\n",
    "\n",
    "celeri.plot_estimation_summary(\n",
    "    command,\n",
    "    segment,\n",
    "    station,\n",
    "    meshes,\n",
    "    estimation_minimize,\n",
    "    lon_range=command.lon_range,\n",
    "    lat_range=command.lat_range,\n",
    "    quiver_scale=command.quiver_scale,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(estimation_qp.strike_slip_rates, \"b+\")\n",
    "plt.plot(estimation_minimize.strike_slip_rates, \"r.\")\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(estimation_qp.tensile_slip_rates, \"b+\")\n",
    "plt.plot(estimation_minimize.tensile_slip_rates, \"r.\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "celeri",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "4d250c5d35aa493295ca814fb3eaa1ee": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "6faf75ca5f3b41388f284e98ec2cf803": {
      "model_module": "jupyter-matplotlib",
      "model_module_version": "^0.9.0",
      "model_name": "ToolbarModel",
      "state": {
       "layout": "IPY_MODEL_9b061db2dc65459ca586b9b9f73c2362",
       "toolitems": [
        [
         "Home",
         "Reset original view",
         "home",
         "home"
        ],
        [
         "Back",
         "Back to previous view",
         "arrow-left",
         "back"
        ],
        [
         "Forward",
         "Forward to next view",
         "arrow-right",
         "forward"
        ],
        [
         "Pan",
         "Left button pans, Right button zooms\nx/y fixes axis, CTRL fixes aspect",
         "arrows",
         "pan"
        ],
        [
         "Zoom",
         "Zoom to rectangle\nx/y fixes axis, CTRL fixes aspect",
         "square-o",
         "zoom"
        ],
        [
         "Download",
         "Download plot",
         "floppy-o",
         "save_figure"
        ]
       ]
      }
     },
     "9b061db2dc65459ca586b9b9f73c2362": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "c25a38234e8f4e818670d9767f95a430": {
      "model_module": "jupyter-matplotlib",
      "model_module_version": "^0.9.0",
      "model_name": "MPLCanvasModel",
      "state": {
       "_cursor": "default",
       "_figure_label": "Figure 1",
       "_height": 708,
       "_width": 1746,
       "layout": "IPY_MODEL_4d250c5d35aa493295ca814fb3eaa1ee",
       "toolbar": "IPY_MODEL_6faf75ca5f3b41388f284e98ec2cf803",
       "toolbar_position": "left"
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
