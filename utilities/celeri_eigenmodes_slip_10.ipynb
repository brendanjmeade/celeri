{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%config InlineBackend.figure_format = \"retina\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import addict\n",
    "import copy\n",
    "import warnings\n",
    "import scipy\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from importlib import reload\n",
    "import matplotlib\n",
    "import cm_xml_to_matplotlib as make_cmap\n",
    "\n",
    "import celeri\n",
    "\n",
    "plt.rcParams[\"text.usetex\"] = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants and parameters\n",
    "N_GRID_X = 100\n",
    "N_GRID_Y = 100\n",
    "\n",
    "cmap = make_cmap.make_cmap(\"w_ymiddle1.xml\")\n",
    "# cmap = cmap.reversed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Common functions\n",
    "# n_grid_x = 100\n",
    "# n_grid_y = 100\n",
    "\n",
    "# cmap = make_cmap.make_cmap(\"w_ymiddle1.xml\")\n",
    "# cmap = cmap.reversed()\n",
    "\n",
    "def inpolygon(xq, yq, xv, yv):\n",
    "    shape = xq.shape\n",
    "    xq = xq.reshape(-1)\n",
    "    yq = yq.reshape(-1)\n",
    "    xv = xv.reshape(-1)\n",
    "    yv = yv.reshape(-1)\n",
    "    q = [(xq[i], yq[i]) for i in range(xq.shape[0])]\n",
    "    p = matplotlib.path.Path([(xv[i], yv[i]) for i in range(xv.shape[0])])\n",
    "    return p.contains_points(q).reshape(shape)\n",
    "\n",
    "\n",
    "def rbf_interpolate(fill_value):\n",
    "    # Observation coordinates and data\n",
    "    x_vec = np.linspace(231, 239, N_GRID_X)\n",
    "    y_vec = np.linspace(38, 52, N_GRID_Y)\n",
    "    x_mat, y_mat = np.meshgrid(x_vec, y_vec)\n",
    "    y_mat = y_mat\n",
    "    centroids_lon = meshes[0].centroids[:, 0]\n",
    "    centroids_lat = meshes[0].centroids[:, 1]\n",
    "    centroids_val = fill_value\n",
    "\n",
    "    # Package for RBFInterpolator\n",
    "    xgrid = np.stack((x_mat, y_mat))\n",
    "    xflat = xgrid.reshape(2, -1).T\n",
    "    xobs = np.vstack((centroids_lon, centroids_lat)).T\n",
    "    yobs = centroids_val\n",
    "    yflat = scipy.interpolate.RBFInterpolator(\n",
    "        xobs, yobs, kernel=\"cubic\", smoothing=0.01, epsilon=1.5\n",
    "    )(xflat)\n",
    "    ygrid = yflat.reshape(N_GRID_X, N_GRID_Y)\n",
    "    return xgrid, ygrid\n",
    "\n",
    "def get_synthetic_displacements(mesh, tri_linear_operator):\n",
    "    \"\"\"\n",
    "    Prescribe dip-slip in a Gaussian pattern\n",
    "    \"\"\"\n",
    "    tri_centroid_to_mesh_lon = mesh.centroids[:, 0] - np.mean(mesh.centroids[:, 0])\n",
    "    tri_centroid_to_mesh_lat = mesh.centroids[:, 1] - np.mean(mesh.centroids[:, 1])\n",
    "\n",
    "    # Hardcoded northern Cascadia example that Jack suggested.\n",
    "    tri_centroid_to_mesh_lon = mesh.centroids[:, 0] - 234.5\n",
    "    tri_centroid_to_mesh_lat = mesh.centroids[:, 1] - 48.5\n",
    "\n",
    "    # Southern Cascadia example\n",
    "    tri_centroid_to_mesh_lon = mesh.centroids[:, 0] - np.mean(mesh.centroids[:, 0]) - 2\n",
    "    tri_centroid_to_mesh_lat = mesh.centroids[:, 1] - np.mean(mesh.centroids[:, 1])\n",
    "\n",
    "    tri_centroid_to_mesh_centroid_distance = np.sqrt(\n",
    "        tri_centroid_to_mesh_lon**2 + tri_centroid_to_mesh_lat**2\n",
    "    )\n",
    "    dip_slip_distribution = np.exp(\n",
    "        -((tri_centroid_to_mesh_centroid_distance / 1.0) ** 2.0)\n",
    "    )\n",
    "    slip_distribution = np.zeros(2 * dip_slip_distribution.size)\n",
    "    slip_distribution[1::2] = dip_slip_distribution  # Dip slip only\n",
    "    slip_distribution[0::2] = 1e-4 * np.random.randn(\n",
    "        dip_slip_distribution.size\n",
    "    )  # Adding a teeny amount of non-zero noise here just so contouring works...ugh\n",
    "    synthetic_displacements = tri_linear_operator @ slip_distribution\n",
    "    return slip_distribution, synthetic_displacements\n",
    "\n",
    "\n",
    "def plot_slip_distributions(\n",
    "    slip_distribution_input, slip_distribution_estimated, suptitle_string\n",
    "):\n",
    "    plt.figure(figsize=(12, 4))\n",
    "\n",
    "    plt.subplot(1, 4, 1)\n",
    "    plt.title(\"input strike-slip\")\n",
    "    interpolate_and_plot(slip_distribution_input[0::2])\n",
    "\n",
    "    plt.subplot(1, 4, 2)\n",
    "    plt.title(\"estimated strike-slip\")\n",
    "    interpolate_and_plot(slip_distribution_estimated[0::2])\n",
    "\n",
    "    plt.subplot(1, 4, 3)\n",
    "    plt.title(\"input dip-slip\")\n",
    "    interpolate_and_plot(slip_distribution_input[1::2])\n",
    "\n",
    "    plt.subplot(1, 4, 4)\n",
    "    plt.title(\"estimated dip-slip\")\n",
    "    interpolate_and_plot(slip_distribution_estimated[1::2])\n",
    "\n",
    "    plt.suptitle(suptitle_string)\n",
    "    plt.show()\n",
    "\n",
    "def interpolate_and_plot(fill_value):\n",
    "    # Interpolate values onto a regular grid for plotting\n",
    "    xgrid, ygrid = rbf_interpolate(fill_value)\n",
    "    xflat = xgrid.reshape(2, -1).T\n",
    "    inpolygon_vals = inpolygon(\n",
    "        xflat[:, 0], xflat[:, 1], meshes[0].x_perimeter, meshes[0].y_perimeter\n",
    "    )\n",
    "    inpolygon_vals = np.reshape(inpolygon_vals, (N_GRID_X, N_GRID_Y))\n",
    "    ygrid[~inpolygon_vals] = np.nan\n",
    "\n",
    "    # Plot\n",
    "    levels = np.linspace(-1.0, 1.0, 6)\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.filterwarnings(\n",
    "            \"ignore\", message=\"No contour levels were found within the data range.\"\n",
    "        )\n",
    "        plt.contourf(*xgrid, ygrid, cmap=cmap, levels=levels, extend=\"both\")\n",
    "        plt.contour(\n",
    "            *xgrid,\n",
    "            ygrid,\n",
    "            colors=\"k\",\n",
    "            linestyles=\"solid\",\n",
    "            linewidths=0.25,\n",
    "            levels=levels,\n",
    "        )\n",
    "    plt.plot(meshes[0].x_perimeter, meshes[0].y_perimeter, \"-k\", linewidth=1.0)\n",
    "    plt.gca().set_aspect(\"equal\", adjustable=\"box\")\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "COMMAND_FILE_NAME = \"../data/command/western_north_america_command.json\"\n",
    "command = celeri.get_command(COMMAND_FILE_NAME)\n",
    "celeri.create_output_folder(command)\n",
    "logger = celeri.get_logger(command)\n",
    "segment, block, meshes, station, mogi, sar = celeri.read_data(command)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_eigenvalues_and_eigenvectors(n_eigenvalues):\n",
    "#     # Calculate Cartesian distances between triangle centroids\n",
    "#     centroid_coordinates = np.array(\n",
    "#         [meshes[0].x_centroid, meshes[0].y_centroid, meshes[0].y_centroid]\n",
    "#     ).T\n",
    "#     distance_matrix = scipy.spatial.distance.cdist(\n",
    "#         centroid_coordinates, centroid_coordinates, \"euclidean\"\n",
    "#     )\n",
    "\n",
    "#     # Rescale distance matrix to the range 0-1\n",
    "#     distance_matrix = (distance_matrix - np.min(distance_matrix)) / np.ptp(\n",
    "#         distance_matrix\n",
    "#     )\n",
    "\n",
    "#     # Calculate correlation matrix\n",
    "#     correlation_matrix = np.exp(-distance_matrix)\n",
    "\n",
    "#     # https://stackoverflow.com/questions/12167654/fastest-way-to-compute-k-largest-eigenvalues-and-corresponding-eigenvectors-with\n",
    "#     eigenvalues, eigenvectors = scipy.linalg.eigh(\n",
    "#         correlation_matrix,\n",
    "#         subset_by_index=[meshes[0].n_tde - n_eigenvalues, meshes[0].n_tde - 1],\n",
    "#     )\n",
    "#     eigenvalues = np.real(eigenvalues)\n",
    "#     eigenvectors = np.real(eigenvectors)\n",
    "#     ordered_index = np.flip(np.argsort(eigenvalues))\n",
    "#     eigenvalues = eigenvalues[ordered_index]\n",
    "#     eigenvectors = eigenvectors[:, ordered_index]\n",
    "#     return eigenvalues, eigenvectors\n",
    "\n",
    "\n",
    "def get_eigenvalues_and_eigenvectors(n_eigenvalues, x, y, z):\n",
    "    n_tde = x.size\n",
    "\n",
    "    # Calculate Cartesian distances between triangle centroids\n",
    "    centroid_coordinates = np.array([x, y, z]).T\n",
    "    distance_matrix = scipy.spatial.distance.cdist(\n",
    "        centroid_coordinates, centroid_coordinates, \"euclidean\"\n",
    "    )\n",
    "\n",
    "    # Rescale distance matrix to the range 0-1\n",
    "    distance_matrix = (distance_matrix - np.min(distance_matrix)) / np.ptp(\n",
    "        distance_matrix\n",
    "    )\n",
    "\n",
    "    # Calculate correlation matrix\n",
    "    correlation_matrix = np.exp(-distance_matrix)\n",
    "\n",
    "    # https://stackoverflow.com/questions/12167654/fastest-way-to-compute-k-largest-eigenvalues-and-corresponding-eigenvectors-with\n",
    "    eigenvalues, eigenvectors = scipy.linalg.eigh(\n",
    "        correlation_matrix,\n",
    "        subset_by_index=[n_tde - n_eigenvalues, n_tde - 1],\n",
    "    )\n",
    "    eigenvalues = np.real(eigenvalues)\n",
    "    eigenvectors = np.real(eigenvectors)\n",
    "    ordered_index = np.flip(np.argsort(eigenvalues))\n",
    "    eigenvalues = eigenvalues[ordered_index]\n",
    "    eigenvectors = eigenvectors[:, ordered_index]\n",
    "    return eigenvalues, eigenvectors\n",
    "\n",
    "\n",
    "# n_eigenvalues = 100\n",
    "# eigenvalues, eigenvectors = get_eigenvalues_and_eigenvectors(\n",
    "#     n_eigenvalues, meshes[0].x_centroid, meshes[0].y_centroid, meshes[0].z_centroid\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_eigenvector_example_plot():\n",
    "    n_eigenvalues = 110\n",
    "    eigenvalues, eigenvectors = get_eigenvalues_and_eigenvectors(\n",
    "        n_eigenvalues, meshes[0].x_centroid, meshes[0].y_centroid, meshes[0].z_centroid\n",
    "    )\n",
    "\n",
    "    # Plot select eigenmodes\n",
    "    plt.figure(figsize=(16, 13))\n",
    "\n",
    "    for i in range(0, 18):\n",
    "        ax = plt.subplot(3, 6, i + 1)\n",
    "\n",
    "        # Shift eigenmodes by plotting row to show some dynamic range\n",
    "        if i > 5 and i <= 11:\n",
    "            i = i - 6 + 30\n",
    "        elif i > 11:\n",
    "            i = i - 12 + 100\n",
    "        fill_value = fill_value = eigenvectors[:, i]\n",
    "\n",
    "        # Normalize fill_value for interpretable plotting\n",
    "        min_value = np.min(fill_value)\n",
    "        max_value = np.max(fill_value)\n",
    "        if np.abs(max_value) > np.abs(min_value):\n",
    "            fill_value = fill_value / max_value\n",
    "        else:\n",
    "            fill_value = fill_value / np.abs(min_value)\n",
    "\n",
    "        if i == 0 and np.nanmean(fill_value) < 0:\n",
    "            fill_value = -1 * fill_value\n",
    "\n",
    "        interpolate_and_plot(fill_value)\n",
    "        plt.title(f\"mode {i}\")\n",
    "\n",
    "    plt.savefig(\"select_eigenmodes.pdf\")\n",
    "    plt.savefig(\"select_eigenmodes.png\", dpi=500)\n",
    "    plt.show()\n",
    "\n",
    "make_eigenvector_example_plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# operators = addict.Dict()\n",
    "tde_matrix = celeri.get_tde_to_velocities(meshes, station, command)\n",
    "# celeri.get_all_mesh_smoothing_matrices(meshes, operators)\n",
    "\n",
    "# Eliminate matrix entries for vertical displacments and tensile slip\n",
    "# tde_matrix = copy.deepcopy(operators.tri_station)\n",
    "tde_matrix = np.delete(tde_matrix, np.arange(2, tde_matrix.shape[0], 3), axis=0)\n",
    "tde_matrix = np.delete(tde_matrix, np.arange(2, tde_matrix.shape[1], 3), axis=1)\n",
    "\n",
    "# Generate synthetic slip source and synthetic displacements\n",
    "slip_distribution, synthetic_displacements = get_synthetic_displacements(\n",
    "    meshes[0], tde_matrix\n",
    ")\n",
    "slip_distribution_strike_slip_true = slip_distribution[0::2]\n",
    "slip_distribution_dip_slip_true = slip_distribution[1::2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Direct least squares estimate with no smoothing\n",
    "slip_distribution_estimated = np.linalg.lstsq(\n",
    "    tde_matrix, synthetic_displacements, rcond=None\n",
    ")\n",
    "\n",
    "plot_slip_distributions(\n",
    "    slip_distribution,\n",
    "    slip_distribution_estimated[0],\n",
    "    suptitle_string=\"np.linalg.lstsq - no smoothing\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eigenvalue slip estimate with dip slip only\n",
    "n_eigenvalues = 30\n",
    "eigenvalues, eigenvectors = get_eigenvalues_and_eigenvectors(\n",
    "    n_eigenvalues, meshes[0].x_centroid, meshes[0].y_centroid, meshes[0].z_centroid\n",
    ")\n",
    "\n",
    "# Select dip-slip only\n",
    "tde_matrix_dip_only = tde_matrix[:, 1::2]\n",
    "\n",
    "print(f\"{eigenvectors.shape=}\")\n",
    "print(f\"{tde_matrix.shape=}\")\n",
    "print(f\"{tde_matrix_dip_only.shape=}\")\n",
    "\n",
    "# Solve for eigenvector weights\n",
    "eigenvector_weights_estimated = (\n",
    "    np.linalg.pinv(tde_matrix_dip_only @ eigenvectors) @ synthetic_displacements\n",
    ")\n",
    "\n",
    "# Recover slip from eigenvector weights\n",
    "slip_distribution_estimated_eigs = (\n",
    "    eigenvectors @ eigenvector_weights_estimated\n",
    ")\n",
    "\n",
    "# Select dip slip only\n",
    "slip_distribution_eigs = np.zeros(2 * eigenvectors.shape[0])\n",
    "slip_distribution_eigs[1::2] = slip_distribution_estimated_eigs\n",
    "\n",
    "plot_slip_distributions(\n",
    "    slip_distribution,\n",
    "    slip_distribution_eigs,\n",
    "    suptitle_string=f\"{n_eigenvalues=}\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 3))\n",
    "plt.plot(slip_distribution_estimated[0][1::2], \"b+\")\n",
    "plt.plot(slip_distribution_eigs[1::2], \"r.\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.0 ('celeri')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "4e02521ee8166e85f0cdf9248b501b87197c4fbf1c25b3c3121662d555f974cc"
   }
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
