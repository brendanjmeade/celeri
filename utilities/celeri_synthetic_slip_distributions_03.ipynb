{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stochastic Kinematically Informed Earthquake Sequences (SKIES)\n",
    "1. Calculate kinematically informed random epicenter\n",
    "     $$P(c(t)) = \\frac{1}{1+e^{-c(t)}} + \\mathrm{history}$$\n",
    "     where $c(t)$ is the coupling rate at time ($t$).  This is an instantaneous formulation.  We could also do this with a more history dependent formulation.  This could include dropping probabilities after an event ruptures a triangular element much like a \"state\" effect.  This could sort of halo certain regions\n",
    "2. Calculate random magnitude from Gutenberg-Richter distribution with a minimum magnitude based on minimum triangle area \n",
    "3. Calculate approximate rupture area, $a$ with empirical scaling law (Allen and Hayes, 2017)\n",
    "4. Find subset of $n$ triangles with areas $a_n$ that sum to $a$ some factor\n",
    "5. Calculate eigenfunctions for these triangles\n",
    "6. Generate random Gaussian slip pattern from randomly weighted eigenvectors\n",
    "7. Sigmoid scaling of slip with distance from the hypocenter so that it tapers to zero at rupture edge\n",
    "8. Rescale random Gaussian slip pattern to get the magnitude correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%config InlineBackend.figure_format = \"retina\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-22T18:29:51.661926Z",
     "iopub.status.busy": "2021-08-22T18:29:51.661659Z",
     "iopub.status.idle": "2021-08-22T18:29:51.956035Z",
     "shell.execute_reply": "2021-08-22T18:29:51.955292Z",
     "shell.execute_reply.started": "2021-08-22T18:29:51.661900Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import addict\n",
    "import copy\n",
    "import warnings\n",
    "import scipy\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from importlib import reload\n",
    "from pprint import pprint\n",
    "import matplotlib\n",
    "import cm_xml_to_matplotlib as make_cmap\n",
    "\n",
    "import celeri\n",
    "\n",
    "plt.rcParams[\"text.usetex\"] = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants and parameters\n",
    "N_GRID_X = 500\n",
    "N_GRID_Y = 500\n",
    "MAKE_EIGENVECTOR_EXAMPLE_PLOT = False\n",
    "N_CONTOUR_LEVELS = 10\n",
    "AREA_SCALING = 1.25 # Increases rupture area to partially compensate for sigmoid filtering\n",
    "\n",
    "KM2_TO_M2 = 1e6 # kilometers squared to meters squared\n",
    "DYNECM_TO_NM = 1e-7 # dynes centimeters to Newton meters\n",
    "SHEAR_MODULUS = 3e10 # Shear modulus (Pa)\n",
    "\n",
    "cmap = make_cmap.make_cmap(\"w_ymiddle1.xml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inpolygon(xq, yq, xv, yv):\n",
    "    shape = xq.shape\n",
    "    xq = xq.reshape(-1)\n",
    "    yq = yq.reshape(-1)\n",
    "    xv = xv.reshape(-1)\n",
    "    yv = yv.reshape(-1)\n",
    "    q = [(xq[i], yq[i]) for i in range(xq.shape[0])]\n",
    "    p = matplotlib.path.Path([(xv[i], yv[i]) for i in range(xv.shape[0])])\n",
    "    return p.contains_points(q).reshape(shape)\n",
    "\n",
    "\n",
    "def rbf_interpolate(fill_value):\n",
    "    # Observation coordinates and data\n",
    "    x_vec = np.linspace(231, 239, N_GRID_X)\n",
    "    y_vec = np.linspace(38, 52, N_GRID_Y)\n",
    "    x_mat, y_mat = np.meshgrid(x_vec, y_vec)\n",
    "    y_mat = y_mat\n",
    "    centroids_lon = meshes[0].centroids[:, 0]\n",
    "    centroids_lat = meshes[0].centroids[:, 1]\n",
    "    centroids_val = fill_value\n",
    "\n",
    "    # Package for RBFInterpolator\n",
    "    xgrid = np.stack((x_mat, y_mat))\n",
    "    xflat = xgrid.reshape(2, -1).T\n",
    "    xobs = np.vstack((centroids_lon, centroids_lat)).T\n",
    "    yobs = centroids_val\n",
    "    yflat = scipy.interpolate.RBFInterpolator(\n",
    "        xobs, yobs, kernel=\"cubic\", smoothing=0.01, epsilon=1.5\n",
    "    )(xflat)\n",
    "    ygrid = yflat.reshape(N_GRID_X, N_GRID_Y)\n",
    "    return xgrid, ygrid\n",
    "\n",
    "\n",
    "def get_synthetic_displacements(mesh, tri_linear_operator):\n",
    "    \"\"\"\n",
    "    Prescribe dip-slip in a Gaussian pattern\n",
    "    \"\"\"\n",
    "    tri_centroid_to_mesh_lon = mesh.centroids[:, 0] - np.mean(mesh.centroids[:, 0])\n",
    "    tri_centroid_to_mesh_lat = mesh.centroids[:, 1] - np.mean(mesh.centroids[:, 1])\n",
    "\n",
    "    # Hardcoded northern Cascadia example that Jack suggested.\n",
    "    tri_centroid_to_mesh_lon = mesh.centroids[:, 0] - 234.5\n",
    "    tri_centroid_to_mesh_lat = mesh.centroids[:, 1] - 48.5\n",
    "\n",
    "    # Southern Cascadia example\n",
    "    tri_centroid_to_mesh_lon = mesh.centroids[:, 0] - np.mean(mesh.centroids[:, 0]) - 2\n",
    "    tri_centroid_to_mesh_lat = mesh.centroids[:, 1] - np.mean(mesh.centroids[:, 1])\n",
    "\n",
    "    tri_centroid_to_mesh_centroid_distance = np.sqrt(\n",
    "        tri_centroid_to_mesh_lon**2 + tri_centroid_to_mesh_lat**2\n",
    "    )\n",
    "    dip_slip_distribution = np.exp(\n",
    "        -((tri_centroid_to_mesh_centroid_distance / 1.0) ** 2.0)\n",
    "    )\n",
    "    slip_distribution = np.zeros(2 * dip_slip_distribution.size)\n",
    "    slip_distribution[1::2] = dip_slip_distribution  # Dip slip only\n",
    "    slip_distribution[0::2] = 1e-4 * np.random.randn(\n",
    "        dip_slip_distribution.size\n",
    "    )  # Adding a teeny amount of non-zero noise here just so contouring works...ugh\n",
    "    synthetic_displacements = tri_linear_operator @ slip_distribution\n",
    "    return slip_distribution, synthetic_displacements\n",
    "\n",
    "\n",
    "def plot_slip_distributions(\n",
    "    slip_distribution_input, slip_distribution_estimated, suptitle_string\n",
    "):\n",
    "    plt.figure(figsize=(12, 4))\n",
    "\n",
    "    plt.subplot(1, 4, 1)\n",
    "    plt.title(\"input strike-slip\")\n",
    "    interpolate_and_plot(slip_distribution_input[0::2])\n",
    "\n",
    "    plt.subplot(1, 4, 2)\n",
    "    plt.title(\"estimated strike-slip\")\n",
    "    interpolate_and_plot(slip_distribution_estimated[0::2])\n",
    "\n",
    "    plt.subplot(1, 4, 3)\n",
    "    plt.title(\"input dip-slip\")\n",
    "    interpolate_and_plot(slip_distribution_input[1::2])\n",
    "\n",
    "    plt.subplot(1, 4, 4)\n",
    "    plt.title(\"estimated dip-slip\")\n",
    "    interpolate_and_plot(slip_distribution_estimated[1::2])\n",
    "\n",
    "    plt.suptitle(suptitle_string)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def interpolate_and_plot(fill_value):\n",
    "    # Interpolate values onto a regular grid for plotting\n",
    "    # If the fill value has very little variation so it can be contoured\n",
    "    if fill_value.ptp() < 1e-4:\n",
    "        fill_value = 1e-4 * np.ones_like(fill_value)\n",
    "\n",
    "    xgrid, ygrid = rbf_interpolate(fill_value)\n",
    "    xflat = xgrid.reshape(2, -1).T\n",
    "    inpolygon_vals = inpolygon(\n",
    "        xflat[:, 0], xflat[:, 1], meshes[0].x_perimeter, meshes[0].y_perimeter\n",
    "    )\n",
    "    inpolygon_vals = np.reshape(inpolygon_vals, (N_GRID_X, N_GRID_Y))\n",
    "    ygrid[~inpolygon_vals] = np.nan\n",
    "\n",
    "    # Plot\n",
    "    levels = np.linspace(-1.0, 1.0, N_CONTOUR_LEVELS)\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.filterwarnings(\n",
    "            \"ignore\", message=\"No contour levels were found within the data range.\"\n",
    "        )\n",
    "        plt.contourf(*xgrid, ygrid, cmap=cmap, levels=levels, extend=\"both\")\n",
    "        plt.contour(\n",
    "            *xgrid,\n",
    "            ygrid,\n",
    "            colors=\"k\",\n",
    "            linestyles=\"solid\",\n",
    "            linewidths=0.25,\n",
    "            levels=levels,\n",
    "        )\n",
    "    plt.plot(meshes[0].x_perimeter, meshes[0].y_perimeter, \"-k\", linewidth=1.0)\n",
    "    plt.gca().set_aspect(\"equal\", adjustable=\"box\")\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "\n",
    "\n",
    "def get_eigenvalues_and_eigenvectors(n_eigenvalues, x, y, z):\n",
    "    n_tde = x.size\n",
    "\n",
    "    # Calculate Cartesian distances between triangle centroids\n",
    "    centroid_coordinates = np.array([x, y, z]).T\n",
    "    distance_matrix = scipy.spatial.distance.cdist(\n",
    "        centroid_coordinates, centroid_coordinates, \"euclidean\"\n",
    "    )\n",
    "\n",
    "    # Rescale distance matrix to the range 0-1\n",
    "    distance_matrix = (distance_matrix - np.min(distance_matrix)) / np.ptp(\n",
    "        distance_matrix\n",
    "    )\n",
    "\n",
    "    # Calculate correlation matrix\n",
    "    correlation_matrix = np.exp(-distance_matrix)\n",
    "\n",
    "    # https://stackoverflow.com/questions/12167654/fastest-way-to-compute-k-largest-eigenvalues-and-corresponding-eigenvectors-with\n",
    "    eigenvalues, eigenvectors = scipy.linalg.eigh(\n",
    "        correlation_matrix,\n",
    "        subset_by_index=[n_tde - n_eigenvalues, n_tde - 1],\n",
    "    )\n",
    "    eigenvalues = np.real(eigenvalues)\n",
    "    eigenvectors = np.real(eigenvectors)\n",
    "    ordered_index = np.flip(np.argsort(eigenvalues))\n",
    "    eigenvalues = eigenvalues[ordered_index]\n",
    "    eigenvectors = eigenvectors[:, ordered_index]\n",
    "    return eigenvalues, eigenvectors\n",
    "\n",
    "\n",
    "def get_synthetic_accumulated_slip(mesh, sources):\n",
    "    slip_distribution = np.zeros(2 * mesh.n_tde)\n",
    "    strike_slip_distribution = np.zeros(mesh.n_tde)\n",
    "    dip_slip_distribution = np.zeros(mesh.n_tde)\n",
    "\n",
    "    for i in range(sources.lon.size):\n",
    "        source_to_mesh_centroid_lon = mesh.centroids[:, 0] - sources.lon[i]\n",
    "        source_to_mesh_centroid_lat = mesh.centroids[:, 1] - sources.lat[i]\n",
    "\n",
    "        source_to_mesh_centroid_distance = np.sqrt(\n",
    "            source_to_mesh_centroid_lon**2.0 + source_to_mesh_centroid_lat**2.0\n",
    "        )\n",
    "\n",
    "        # Guassian slip pattern\n",
    "        if sources.slip_type[i] == \"strike_slip\":\n",
    "            strike_slip_distribution += sources.magnitude[i] * np.exp(\n",
    "                -((source_to_mesh_centroid_distance / 1.0) ** 2.0)\n",
    "            )\n",
    "        elif sources.slip_type[i] == \"dip_slip\":\n",
    "            dip_slip_distribution += sources.magnitude[i] * np.exp(\n",
    "                -((source_to_mesh_centroid_distance / 1.0) ** 2.0)\n",
    "            )\n",
    "\n",
    "    slip_distribution[0::2] = strike_slip_distribution  # Strike slip only\n",
    "    slip_distribution[1::2] = dip_slip_distribution  # Dip slip only\n",
    "    return slip_distribution\n",
    "\n",
    "\n",
    "def plot_meshes(meshes, fill_value, ax, cmap_string):\n",
    "    x_coords = meshes[0].meshio_object.points[:, 0]\n",
    "    y_coords = meshes[0].meshio_object.points[:, 1]\n",
    "    vertex_array = np.asarray(meshes[0].verts)\n",
    "\n",
    "    if not ax:\n",
    "        ax = plt.gca()\n",
    "    xy = np.c_[x_coords, y_coords]\n",
    "    verts = xy[vertex_array]\n",
    "    pc = matplotlib.collections.PolyCollection(\n",
    "        verts,\n",
    "        edgecolor=\"k\",\n",
    "        cmap=cmap_string,\n",
    "        linewidth=0.1,\n",
    "        alpha=1.0,\n",
    "    )\n",
    "    pc.set_array(fill_value)\n",
    "    ax.add_collection(pc)\n",
    "    ax.autoscale()\n",
    "    plt.gca().set_aspect(\"equal\")\n",
    "    return pc\n",
    "\n",
    "\n",
    "def moment_magnitude_to_area_allen_and_hayes(moment_magnitude):\n",
    "    \"\"\"Calculate emperically estimated slip areas using\n",
    "    relationships from:\n",
    "\n",
    "    Allen and Hayes (2017), Alternative Rupture-Scaling\n",
    "    Relationships for Subduction Interface and Other Offshore\n",
    "    Environments, Bulletin of the Seismological Society of America,\n",
    "    Vol. 107, No. 3, pp. 1240–1253, June 2017, doi: 10.1785/0120160255\n",
    "\n",
    "    All values taken from their table 2\n",
    "\n",
    "    Note: $S_2$ in the paper's notation is what we use for rupture_area\n",
    "\n",
    "    Args:\n",
    "        moment_magnitude: Array of moment magnitudes\n",
    "\n",
    "    Returns:\n",
    "        area: rupture area in meters squared\n",
    "    \"\"\"\n",
    "    hinge_moment_magnitude = 8.63\n",
    "    if moment_magnitude <= hinge_moment_magnitude:\n",
    "        a = -5.62\n",
    "        b = 1.22\n",
    "    elif moment_magnitude > hinge_moment_magnitude:\n",
    "        a = 2.23\n",
    "        b = 0.31\n",
    "    area = KM2_TO_M2 * 10 ** (a + b * moment_magnitude)\n",
    "    return area\n",
    "\n",
    "\n",
    "def get_gutenberg_richter_magnitudes(n_earthquakes, b_value, minimum_magnitude):\n",
    "    rng = np.random.RandomState()\n",
    "    magnitudes = minimum_magnitude + rng.exponential(\n",
    "        1.0 / (-b_value / np.log10(np.e)), n_earthquakes\n",
    "    )\n",
    "    return magnitudes\n",
    "\n",
    "\n",
    "def normalized_sigmoid(a, b, x):\n",
    "    \"\"\"\n",
    "    Returns array of a horizontal mirrored normalized sigmoid function\n",
    "    output between 0 and 1\n",
    "    Function parameters a = center; b = width\n",
    "    https://stackoverflow.com/questions/3985619/how-to-calculate-a-logistic-sigmoid-function-in-python\n",
    "    \"\"\"\n",
    "    s = 1 / (1 + np.exp(b * (x - a)))\n",
    "    return 1 * (s - np.min(s)) / (np.max(s) - np.min(s))  # normalize function to 0-1\n",
    "\n",
    "\n",
    "# Visualize eigenvectors\n",
    "def interpolate_and_plot(fill_value):\n",
    "    # Interpolate values onto a regular grid for plotting\n",
    "    # If the fill value has very little variation so it can be contoured\n",
    "    if fill_value.ptp() < 1e-4:\n",
    "        fill_value = 1e-4 * np.ones_like(fill_value)\n",
    "\n",
    "    xgrid, ygrid = rbf_interpolate(fill_value)\n",
    "    xflat = xgrid.reshape(2, -1).T\n",
    "    inpolygon_vals = inpolygon(\n",
    "        xflat[:, 0], xflat[:, 1], meshes[0].x_perimeter, meshes[0].y_perimeter\n",
    "    )\n",
    "    inpolygon_vals = np.reshape(inpolygon_vals, (N_GRID_X, N_GRID_Y))\n",
    "    ygrid[~inpolygon_vals] = np.nan\n",
    "\n",
    "    # Plot\n",
    "    levels = np.linspace(-1.0, 1.0, N_CONTOUR_LEVELS)\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.filterwarnings(\n",
    "            \"ignore\", message=\"No contour levels were found within the data range.\"\n",
    "        )\n",
    "        plt.contourf(*xgrid, ygrid, cmap=cmap, levels=levels, extend=\"both\")\n",
    "        plt.contour(\n",
    "            *xgrid,\n",
    "            ygrid,\n",
    "            colors=\"k\",\n",
    "            linestyles=\"solid\",\n",
    "            linewidths=0.25,\n",
    "            levels=levels,\n",
    "        )\n",
    "    plt.plot(meshes[0].x_perimeter, meshes[0].y_perimeter, \"-k\", linewidth=1.0)\n",
    "    plt.gca().set_aspect(\"equal\", adjustable=\"box\")\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "\n",
    "\n",
    "def get_hypocenter_triangle_to_all_triangles_distances(meshes, event):\n",
    "    # Find distance between current index mesh triangle all others\n",
    "    x_centroid = (\n",
    "        meshes[0].x_centroid[event.hypocenter_triangle_index] - meshes[0].x_centroid\n",
    "    )\n",
    "    y_centroid = (\n",
    "        meshes[0].y_centroid[event.hypocenter_triangle_index] - meshes[0].y_centroid\n",
    "    )\n",
    "    z_centroid = (\n",
    "        meshes[0].z_centroid[event.hypocenter_triangle_index] - meshes[0].z_centroid\n",
    "    )\n",
    "\n",
    "    all_triangle_cartesian_centroid_coordinates = np.vstack(\n",
    "        (x_centroid, y_centroid, z_centroid)\n",
    "    ).T\n",
    "\n",
    "    hypocenter_triangle_cartesian_centroid_coordinates = np.array(\n",
    "        [\n",
    "            x_centroid[event.hypocenter_triangle_index],\n",
    "            y_centroid[event.hypocenter_triangle_index],\n",
    "            z_centroid[event.hypocenter_triangle_index],\n",
    "        ]\n",
    "    ).T\n",
    "\n",
    "    hypocenter_triangle_to_all_triangles_distances = scipy.spatial.distance.cdist(\n",
    "        hypocenter_triangle_cartesian_centroid_coordinates,\n",
    "        all_triangle_cartesian_centroid_coordinates,\n",
    "        \"euclidean\",\n",
    "    )\n",
    "\n",
    "    hypocenter_triangle_to_all_triangles_distances = np.squeeze(\n",
    "        hypocenter_triangle_to_all_triangles_distances\n",
    "    )\n",
    "\n",
    "    return hypocenter_triangle_to_all_triangles_distances\n",
    "\n",
    "\n",
    "def event_generate_slip(event, eigenvalues, eigenvectors):\n",
    "    event.slip = np.zeros(event.triangle_index.size)\n",
    "    weights = np.random.randn(eigenvalues.size)\n",
    "    for k in range(1, weights.size):\n",
    "        event.slip += weights[k] * np.sqrt(eigenvalues[k]) * eigenvectors[:, k]\n",
    "    event.slip = np.exp(event.slip)\n",
    "\n",
    "    # Apply taper to slip.  This is ad hoc and may need revision\n",
    "    distances = event.hypocenter_triangle_to_all_triangles_distances[\n",
    "        event.triangle_index\n",
    "    ]\n",
    "    taper_transition = 1.5 * np.mean(distances)\n",
    "    taper_width = 10 / taper_transition  # m\n",
    "\n",
    "    slip_taper = normalized_sigmoid(taper_transition, taper_width, distances)\n",
    "    event.slip = event.slip * slip_taper\n",
    "\n",
    "    # After taper is applied rescale slip magnitudes to get the correct moment\n",
    "    event.pre_scaled_moment = SHEAR_MODULUS * np.sum(\n",
    "        event.slip * meshes[0].areas[event.triangle_index]\n",
    "    )\n",
    "    event.slip_scaling_factor = event.moment / event.pre_scaled_moment\n",
    "    event.slip = event.slip * event.slip_scaling_factor\n",
    "\n",
    "    event.slip_all_elements = np.zeros(meshes[0].n_tde)\n",
    "    event.slip_all_elements[event.triangle_index] = event.slip\n",
    "\n",
    "    return event\n",
    "\n",
    "\n",
    "def plot_initial_data(meshes, initial_slip_deficit):\n",
    "    # Plot all mesh data and initial slip deficit condition\n",
    "    plt.figure(figsize=(15, 4))\n",
    "    plt.subplot(1, 4, 1)\n",
    "    pc = plot_meshes(meshes, np.zeros(meshes[0].areas.size), plt.gca(), \"Blues\")\n",
    "    plt.plot(meshes[0].x_perimeter, meshes[0].y_perimeter, \"-k\")\n",
    "    plt.title(f\"{meshes[0].n_tde} triangles\")\n",
    "\n",
    "    plt.subplot(1, 4, 2)\n",
    "    pc = plot_meshes(meshes, meshes[0].areas / 1e6, plt.gca(), \"plasma\")\n",
    "    plt.colorbar(pc, label=\"triangle areas (km^2)\")\n",
    "    plt.plot(meshes[0].x_perimeter, meshes[0].y_perimeter, \"-k\")\n",
    "    plt.title(f\"{np.sum(meshes[0].areas) / KM2_TO_M2:0.2f} (km^2)\")\n",
    "\n",
    "    plt.subplot(1, 4, 3)\n",
    "    pc = plot_meshes(meshes, initial_slip_deficit, plt.gca(), \"inferno_r\")\n",
    "    plt.colorbar(pc, label=\"initial slip deficit (m)\")\n",
    "    plt.plot(meshes[0].x_perimeter, meshes[0].y_perimeter, \"-k\")\n",
    "    plt.title(f\"{np.max(initial_slip_deficit):0.2f} (m)\")\n",
    "\n",
    "\n",
    "def plot_event(event, meshes, pre_event_slip_deficit, probability, post_event_slip_deficit, t):\n",
    "    # Plot distances from current event hypocenter triangle\n",
    "    plt.figure(figsize=(20, 3))\n",
    "\n",
    "    # Plot pre-earthquake slip deficit\n",
    "    plt.subplot(1, 6, 1)\n",
    "    pc = plot_meshes(meshes, pre_event_slip_deficit, plt.gca(), \"magma_r\")\n",
    "    plt.colorbar(pc, label=\"initial slip deficit (m)\")\n",
    "    plt.plot(meshes[0].x_perimeter, meshes[0].y_perimeter, \"-k\")\n",
    "    plt.title(f\"pre-earthquake slip deficit\")\n",
    "\n",
    "    # Plot current probability\n",
    "    plt.subplot(1, 6, 2)\n",
    "    pc = plot_meshes(meshes, probability, plt.gca(), \"viridis_r\")\n",
    "    plt.colorbar(pc, label=\"initial slip deficit (m)\")\n",
    "    plt.plot(meshes[0].x_perimeter, meshes[0].y_perimeter, \"-k\")\n",
    "    plt.title(f\"probability\")\n",
    "\n",
    "    plt.subplot(1, 6, 3)\n",
    "    pc = plot_meshes(\n",
    "        meshes,\n",
    "        event.hypocenter_triangle_to_all_triangles_distances / 1e3,\n",
    "        plt.gca(),\n",
    "        \"Reds\",\n",
    "    )\n",
    "    plt.colorbar(pc, label=\"distance to hypocenter triangle\")\n",
    "    plt.plot(\n",
    "        meshes[0].centroids[event.hypocenter_triangle_index, 0],\n",
    "        meshes[0].centroids[event.hypocenter_triangle_index, 1],\n",
    "        \"*k\",\n",
    "        markersize=15,\n",
    "    )\n",
    "    plt.plot(meshes[0].x_perimeter, meshes[0].y_perimeter, \"-k\")\n",
    "    plt.title(f\"index = {event.hypocenter_triangle_index[0]}\")\n",
    "\n",
    "    # Plot triangles involved in current event\n",
    "    plt.subplot(1, 6, 4)\n",
    "    fill_value = np.zeros(meshes[0].n_tde)\n",
    "    fill_value[event.triangle_index] = 1\n",
    "    pc = plot_meshes(meshes, fill_value, plt.gca(), \"Blues\")\n",
    "    plt.colorbar(pc, label=\"event triangles\")\n",
    "    plt.plot(meshes[0].x_perimeter, meshes[0].y_perimeter, \"-k\")\n",
    "    plt.title(f\"{event.actual_area / KM2_TO_M2:0.2f} (km)\")\n",
    "\n",
    "    # Plot slip distribution\n",
    "    plt.subplot(1, 6, 5)\n",
    "    fill_value = np.zeros(meshes[0].n_tde)\n",
    "    fill_value[event.triangle_index] = event.slip\n",
    "    x_coords = meshes[0].meshio_object.points[:, 0]\n",
    "    y_coords = meshes[0].meshio_object.points[:, 1]\n",
    "    vertex_array = np.asarray(meshes[0].verts)\n",
    "    ax = plt.gca()\n",
    "    xy = np.c_[x_coords, y_coords]\n",
    "    verts = xy[vertex_array]\n",
    "    pc = matplotlib.collections.PolyCollection(\n",
    "        verts,\n",
    "        edgecolor=None,\n",
    "        cmap=\"gnuplot2_r\",\n",
    "        linewidth=0,\n",
    "        alpha=1.0,\n",
    "    )\n",
    "    pc.set_array(fill_value)\n",
    "    ax.add_collection(pc)\n",
    "    ax.autoscale()\n",
    "    plt.gca().set_aspect(\"equal\")\n",
    "    plt.plot(meshes[0].x_perimeter, meshes[0].y_perimeter, \"-k\")\n",
    "    plt.colorbar(pc, label=\"slip (m)\")\n",
    "    plt.title(f\"M_W = {event.moment_magnitude[0]:0.3}\")\n",
    "\n",
    "    plt.subplot(1, 6, 6)\n",
    "    pc = plot_meshes(meshes, post_event_slip_deficit, plt.gca(), \"magma_r\")\n",
    "    plt.colorbar(pc, label=\"slip deficit (m)\")\n",
    "    plt.plot(meshes[0].x_perimeter, meshes[0].y_perimeter, \"-k\")\n",
    "    plt.title(f\"post-earthquake slip deficit\")\n",
    "\n",
    "    plt.suptitle(f\"{t=}\")\n",
    "    plt.show()\n",
    "\n",
    "def area_to_moment_magnitude_allen_and_hayes(area):\n",
    "    \"\"\"Calculate emperically estimated slip areas using\n",
    "    relationships from:\n",
    "\n",
    "    Allen and Hayes (2017), Alternative Rupture-Scaling\n",
    "    Relationships for Subduction Interface and Other Offshore\n",
    "    Environments, Bulletin of the Seismological Society of America,\n",
    "    Vol. 107, No. 3, pp. 1240–1253, June 2017, doi: 10.1785/0120160255\n",
    "\n",
    "    All values taken from their table 2\n",
    "\n",
    "    Note: $S_2$ in the paper's notation is what we use for rupture_area\n",
    "\n",
    "    Args:\n",
    "        moment_magnitude: Array of moment magnitudes\n",
    "\n",
    "    Returns:\n",
    "        area: rupture area in meters squared\n",
    "    \"\"\"\n",
    "    hinge_area = 80714792455.11925 # (m)\n",
    "    if area <= hinge_area:\n",
    "        a = -5.62\n",
    "        b = 1.22\n",
    "    elif area > hinge_area:\n",
    "        a = 2.23\n",
    "        b = 0.31\n",
    "    moment_magnitude = (np.log10(area / KM2_TO_M2) - a) / b\n",
    "    return moment_magnitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_event(meshes, probability):\n",
    "    # Dictionary for storing `event` information for a single earthquake\n",
    "    event = addict.Dict()\n",
    "\n",
    "    # Select random event magnitude from GR distribution\n",
    "    n_earthquakes = 1\n",
    "    b_value = -1.0\n",
    "    minimum_magnitude = 8.0\n",
    "    event.moment_magnitude = get_gutenberg_richter_magnitudes(\n",
    "        n_earthquakes, b_value, minimum_magnitude\n",
    "    )\n",
    "\n",
    "    event.moment = 10 ** (1.5 * (event.moment_magnitude + 10.7) - 7.0)\n",
    "    event.target_area = AREA_SCALING * moment_magnitude_to_area_allen_and_hayes(event.moment_magnitude)\n",
    "    event.total_mesh_area = np.sum(meshes[0].areas)\n",
    "\n",
    "    # Select random triangle, should be based on coupling or slip deficit rate/history\n",
    "    triangle_probabilities = probability\n",
    "    event.hypocenter_triangle_index = np.random.choice(\n",
    "        meshes[0].n_tde, 1, p=triangle_probabilities\n",
    "    )\n",
    "\n",
    "    # Calculate distance from hypocenter triangle toto all other triangles\n",
    "    event.hypocenter_triangle_to_all_triangles_distances = (\n",
    "        get_hypocenter_triangle_to_all_triangles_distances(meshes, event)\n",
    "    )\n",
    "\n",
    "    # Find the triangles close to the hypocenter that accumulate enough area to be a\n",
    "    # part of the event rupture\n",
    "    sorted_distance_index = np.argsort(\n",
    "        event.hypocenter_triangle_to_all_triangles_distances\n",
    "    )\n",
    "    cumulative_area = np.cumsum(meshes[0].areas[sorted_distance_index])\n",
    "    event.triangle_index = sorted_distance_index[\n",
    "        np.where(cumulative_area < event.target_area)[0]\n",
    "    ]\n",
    "    event.actual_area = np.sum(meshes[0].areas[event.triangle_index])\n",
    "    event.mean_slip = event.moment / (SHEAR_MODULUS * event.actual_area)\n",
    "\n",
    "    # Calculate eigenvalues and eigenvectors for the current event area\n",
    "    # Were not storing these in event because that would start to consume a\n",
    "    # lot of RAM as we build histories of multiple events\n",
    "    event.n_eigenvalues = event.triangle_index.size\n",
    "    eigenvalues, eigenvectors = get_eigenvalues_and_eigenvectors(\n",
    "        event.n_eigenvalues,\n",
    "        (meshes[0].x_centroid[event.hypocenter_triangle_index] - meshes[0].x_centroid)[\n",
    "            event.triangle_index\n",
    "        ],\n",
    "        (meshes[0].y_centroid[event.hypocenter_triangle_index] - meshes[0].y_centroid)[\n",
    "            event.triangle_index\n",
    "        ],\n",
    "        (meshes[0].z_centroid[event.hypocenter_triangle_index] - meshes[0].z_centroid)[\n",
    "            event.triangle_index\n",
    "        ],\n",
    "    )\n",
    "\n",
    "    # Generate random slip distribution for current rupture patch\n",
    "    event = event_generate_slip(event, eigenvalues, eigenvectors)\n",
    "    return event\n",
    "\n",
    "\n",
    "def get_probability(slip_deficit, t):\n",
    "    # Map slip defict to earthquake probability\n",
    "    slip_deficit[slip_deficit < 0.0 ] = 0.0\n",
    "    probability = 1 - normalized_sigmoid(1e-5, 1e-1, slip_deficit)\n",
    "    probability = probability - np.min(probability)\n",
    "    probability = probability / np.max(probability)\n",
    "    probability = probability / np.sum(probability)\n",
    "    return probability\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-22T18:29:53.570589Z",
     "iopub.status.busy": "2021-08-22T18:29:53.570331Z",
     "iopub.status.idle": "2021-08-22T18:30:09.817977Z",
     "shell.execute_reply": "2021-08-22T18:30:09.817443Z",
     "shell.execute_reply.started": "2021-08-22T18:29:53.570561Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# COMMAND_FILE_NAME = \"../data/command/western_north_america_command_dense.json\"\n",
    "COMMAND_FILE_NAME = \"../data/command/western_north_america_command.json\"\n",
    "\n",
    "command = celeri.get_command(COMMAND_FILE_NAME)\n",
    "celeri.create_output_folder(command)\n",
    "logger = celeri.get_logger(command)\n",
    "segment, block, meshes, station, mogi, sar = celeri.read_data(command)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set initial conditions with accumulated slip\n",
    "sources = addict.Dict()\n",
    "sources.lon = np.array([235.779])\n",
    "sources.lat = np.array([45.553])\n",
    "sources.magnitude = np.array([30.0])\n",
    "sources.slip_type = [\"dip_slip\"]\n",
    "initial_slip_deficit = get_synthetic_accumulated_slip(meshes[0], sources)\n",
    "initial_dip_slip_deficit = initial_slip_deficit[1::2]\n",
    "slip_deficit = np.copy(initial_dip_slip_deficit)\n",
    "plot_initial_data(meshes, initial_dip_slip_deficit)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = 0\n",
    "probability = get_probability(initial_dip_slip_deficit, t)\n",
    "pre_event_slip_deficit = initial_dip_slip_deficit\n",
    "event = create_event(meshes, probability)\n",
    "post_event_slip_deficit = slip_deficit - event.slip_all_elements\n",
    "plot_event(event, meshes, pre_event_slip_deficit, probability, post_event_slip_deficit, t)\n",
    "\n",
    "print(\"Event data:\")\n",
    "print(f\"Hypocenter longitude = {meshes[0].centroids[event.hypocenter_triangle_index, 0][0]:0.4f} (deg)\")\n",
    "print(f\"Hypocenter latitude = {meshes[0].centroids[event.hypocenter_triangle_index, 1][0]:0.4f} (deg)\")\n",
    "print(f\"Hypocenter depth = {meshes[0].centroids[event.hypocenter_triangle_index, 2][0]:0.4f} (km)\")\n",
    "print(f\"Hypocenter triangle index = {event.hypocenter_triangle_index[0]}\")\n",
    "print(f\"Mean slip = {np.mean(event.slip):0.2f} (m)\")\n",
    "print(f\"Minimum slip = {np.min(event.slip):0.2f} (m)\")\n",
    "print(f\"Maximum slip = {np.max(event.slip):0.2f} (m)\")\n",
    "print(f\"Moment magnitude = {event.moment_magnitude[0]}\")\n",
    "print(f\"Moment = {event.moment[0]:0.3} (N m)\")\n",
    "print(f\"Number of eigenvalues = {event.n_eigenvalues}\")\n",
    "print(f\"Rupture area = {event.actual_area / 1e6:0.2f} (km^2)\")\n",
    "print(f\"Scaling law rupture area = {event.target_area[0] / 1e6:0.2f} (km^2)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_event_slip_deficit = post_event_slip_deficit\n",
    "probability = get_probability(pre_event_slip_deficit, t)\n",
    "event = create_event(meshes, probability)\n",
    "post_event_slip_deficit = pre_event_slip_deficit - event.slip_all_elements\n",
    "plot_event(event, meshes, pre_event_slip_deficit, probability, post_event_slip_deficit, t)\n",
    "\n",
    "print(\"Event data:\")\n",
    "print(f\"Hypocenter longitude = {meshes[0].centroids[event.hypocenter_triangle_index, 0][0]:0.4f} (deg)\")\n",
    "print(f\"Hypocenter latitude = {meshes[0].centroids[event.hypocenter_triangle_index, 1][0]:0.4f} (deg)\")\n",
    "print(f\"Hypocenter depth = {meshes[0].centroids[event.hypocenter_triangle_index, 2][0]:0.4f} (km)\")\n",
    "print(f\"Hypocenter triangle index = {event.hypocenter_triangle_index[0]}\")\n",
    "print(f\"Mean slip = {np.mean(event.slip):0.2f} (m)\")\n",
    "print(f\"Minimum slip = {np.min(event.slip):0.2f} (m)\")\n",
    "print(f\"Maximum slip = {np.max(event.slip):0.2f} (m)\")\n",
    "print(f\"Moment magnitude = {event.moment_magnitude[0]}\")\n",
    "print(f\"Moment = {event.moment[0]:0.3} (N m)\")\n",
    "print(f\"Number of eigenvalues = {event.n_eigenvalues}\")\n",
    "print(f\"Rupture area = {event.actual_area / 1e6:0.2f} (km^2)\")\n",
    "print(f\"Scaling law rupture area = {event.target_area[0] / 1e6:0.2f} (km^2)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Remove dependence on celeri?  Extract mesh read in function? Just read a mesh_parameters.json file?\n",
    "# TODO: Case for when area is a single triangle or less\n",
    "# TODO: Set minimum earthquake size based on smallest mesh element\n",
    "# TODO: Name for slip deficit at each time step\n",
    "# TODO: Track slip in time\n",
    "# TODO: Write up eigenvalue shape idea\n",
    "# TODO: Move text reporting to function\n",
    "# TODO: Write looping logic\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Potential event magnitude\n",
    "minimum_single_triangle_moment_magnitude = area_to_moment_magnitude_allen_and_hayes(\n",
    "    np.min(meshes[0].areas)\n",
    ")\n",
    "print(minimum_single_triangle_moment_magnitude)\n",
    "maximum_single_triangle_moment_magnitude = area_to_moment_magnitude_allen_and_hayes(\n",
    "    np.max(meshes[0].areas)\n",
    ")\n",
    "print(maximum_single_triangle_moment_magnitude)\n",
    "maximum_moment_magnitude = area_to_moment_magnitude_allen_and_hayes(\n",
    "    np.sum(meshes[0].areas)\n",
    ")\n",
    "print(maximum_moment_magnitude)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.0 ('celeri')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "4e02521ee8166e85f0cdf9248b501b87197c4fbf1c25b3c3121662d555f974cc"
   }
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "4d250c5d35aa493295ca814fb3eaa1ee": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "6faf75ca5f3b41388f284e98ec2cf803": {
      "model_module": "jupyter-matplotlib",
      "model_module_version": "^0.9.0",
      "model_name": "ToolbarModel",
      "state": {
       "layout": "IPY_MODEL_9b061db2dc65459ca586b9b9f73c2362",
       "toolitems": [
        [
         "Home",
         "Reset original view",
         "home",
         "home"
        ],
        [
         "Back",
         "Back to previous view",
         "arrow-left",
         "back"
        ],
        [
         "Forward",
         "Forward to next view",
         "arrow-right",
         "forward"
        ],
        [
         "Pan",
         "Left button pans, Right button zooms\nx/y fixes axis, CTRL fixes aspect",
         "arrows",
         "pan"
        ],
        [
         "Zoom",
         "Zoom to rectangle\nx/y fixes axis, CTRL fixes aspect",
         "square-o",
         "zoom"
        ],
        [
         "Download",
         "Download plot",
         "floppy-o",
         "save_figure"
        ]
       ]
      }
     },
     "9b061db2dc65459ca586b9b9f73c2362": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "c25a38234e8f4e818670d9767f95a430": {
      "model_module": "jupyter-matplotlib",
      "model_module_version": "^0.9.0",
      "model_name": "MPLCanvasModel",
      "state": {
       "_cursor": "default",
       "_figure_label": "Figure 1",
       "_height": 708,
       "_width": 1746,
       "layout": "IPY_MODEL_4d250c5d35aa493295ca814fb3eaa1ee",
       "toolbar": "IPY_MODEL_6faf75ca5f3b41388f284e98ec2cf803",
       "toolbar_position": "left"
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
