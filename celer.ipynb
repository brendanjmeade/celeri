{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "%matplotlib widget\n",
    "import copy\n",
    "import datetime\n",
    "import json\n",
    "import os\n",
    "import scipy.spatial\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from importlib import reload\n",
    "\n",
    "import celeri\n",
    "celeri = reload(celeri)"
   ],
   "outputs": [],
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-04T03:00:09.278922Z",
     "iopub.status.busy": "2021-08-04T03:00:09.278702Z",
     "iopub.status.idle": "2021-08-04T03:00:09.389124Z",
     "shell.execute_reply": "2021-08-04T03:00:09.388173Z",
     "shell.execute_reply.started": "2021-08-04T03:00:09.278899Z"
    },
    "tags": []
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "RUN_NAME = datetime.datetime.now().strftime(\"%y%m%d%H%M%S\") + os.sep\n",
    "with open('./data/western_north_america/command.json', 'r') as f:\n",
    "    command = json.load(f)\n",
    "station = pd.read_csv(command[\"station_file_name\"])\n",
    "segment = pd.read_csv(command[\"segment_file_name\"])\n",
    "block = pd.read_csv(command[\"block_file_name\"])"
   ],
   "outputs": [],
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-04T03:00:11.065032Z",
     "iopub.status.busy": "2021-08-04T03:00:11.064786Z",
     "iopub.status.idle": "2021-08-04T03:00:11.092432Z",
     "shell.execute_reply": "2021-08-04T03:00:11.091782Z",
     "shell.execute_reply.started": "2021-08-04T03:00:11.065007Z"
    },
    "tags": []
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "station = celeri.process_station(station, command)\n",
    "segment = celeri.process_segment(segment, command)"
   ],
   "outputs": [],
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-04T03:00:12.007541Z",
     "iopub.status.busy": "2021-08-04T03:00:12.007316Z",
     "iopub.status.idle": "2021-08-04T03:00:12.293727Z",
     "shell.execute_reply": "2021-08-04T03:00:12.293008Z",
     "shell.execute_reply.started": "2021-08-04T03:00:12.007517Z"
    },
    "tags": []
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "np_segments = np.zeros((len(segment), 2, 2))\n",
    "np_segments[:, 0, 0] = segment.lon1.to_numpy()\n",
    "np_segments[:, 1, 0] = segment.lon2.to_numpy()\n",
    "np_segments[:, 0, 1] = segment.lat1.to_numpy()\n",
    "np_segments[:, 1, 1] = segment.lat2.to_numpy()"
   ],
   "outputs": [],
   "metadata": {
    "tags": []
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# De-duplicate the vertices and build an ptr_edge array\n",
    "all_vertices = np_segments.reshape((-1, 2))\n",
    "tree = scipy.spatial.KDTree(all_vertices, leafsize=1000)\n",
    "duplicates = tree.query_ball_point(all_vertices, 1e-8)\n",
    "\n",
    "ptr_edges = []\n",
    "dedup_vertices = []\n",
    "original_to_new = dict()\n",
    "for i in range(np_segments.shape[0]):\n",
    "    v1_idx = duplicates[2 * i][0]\n",
    "    v2_idx = duplicates[2 * i + 1][0]\n",
    "    if v1_idx == 2 * i:\n",
    "        original_to_new[2 * i] = len(dedup_vertices)\n",
    "        dedup_vertices.append(np_segments[i][0])\n",
    "    if v2_idx == 2 * i + 1:\n",
    "        original_to_new[2 * i + 1] = len(dedup_vertices)\n",
    "        dedup_vertices.append(np_segments[i][1])\n",
    "    ptr_edges.append((original_to_new[v1_idx], original_to_new[v2_idx]))\n",
    "\n",
    "np_dedup_vertices = np.array(dedup_vertices)\n",
    "\n",
    "# Check that the vertices are unique up to 1e-8 now.\n",
    "new_tree = scipy.spatial.KDTree(np_dedup_vertices)\n",
    "np.all([v[0] == i for i,v in enumerate(new_tree.query_ball_point(np_dedup_vertices, 1e-8))])\n",
    "\n",
    "# Build the graph\n",
    "G = nx.Graph()\n",
    "for e in ptr_edges:\n",
    "    G.add_edge(*e)\n",
    "\n",
    "# Check that it is planar and build the PlanarEmbedding data structure.\n",
    "is_planar, planar_embedding = nx.check_planarity(G)\n",
    "\n",
    "# Extract each polygon. \n",
    "counted_half_edges = set()\n",
    "polygons = []\n",
    "for component in nx.connected_components(planar_embedding):\n",
    "    for v in component:\n",
    "        for w in planar_embedding.neighbors_cw_order(v):\n",
    "            if (v, w) not in counted_half_edges:\n",
    "                polygons.append(planar_embedding.traverse_face(v, w, counted_half_edges))\n",
    "\n",
    "print(\"Found \" + str(len(polygons)) + \" closed polygons\")\n",
    "\n",
    "# Map polygons boundaries back to 2 labesl for each block\n",
    "n_vertices = np_dedup_vertices.shape[0]\n",
    "n_edges = len(ptr_edges)\n",
    "\n",
    "vertex_to_polygon = [[] for i in range(n_vertices)] \n",
    "for p_idx, p in enumerate(polygons):\n",
    "    for v_idx in p:\n",
    "        vertex_to_polygon[v_idx].append(p_idx)\n",
    "\n",
    "edge_to_polygon = []\n",
    "for e in ptr_edges:\n",
    "    polys_v0 = vertex_to_polygon[e[0]]\n",
    "    polys_v1 = vertex_to_polygon[e[1]]\n",
    "    polys_edge = [p_idx for p_idx in polys_v0 if p_idx in polys_v1] # Intersection of lists\n",
    "    edge_to_polygon.append(polys_edge)\n",
    "\n",
    "segment[\"initial_label1\"] = np.array(edge_to_polygon)[:, 0]\n",
    "segment[\"initial_label2\"] = np.array(edge_to_polygon)[:, 1]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "longitude_east_offset = 1e-3\n",
    "unprocessed_value = 99\n",
    "correct_east_labels = unprocessed_value * np.ones(len(segment))\n",
    "correct_west_labels = unprocessed_value * np.ones(len(segment))\n",
    "\n",
    "for current_block_label in range(len(polygons)):\n",
    "    current_block_idx = np.union1d(segment.index[segment.initial_label1 == current_block_label],\n",
    "                                   segment.index[segment.initial_label2 == current_block_label])\n",
    "    segment_current_block = segment.iloc[current_block_idx]\n",
    "    polygon_vertex_idx = polygons[current_block_label]\n",
    "    vertices_current_block = np.concatenate([np_dedup_vertices[polygon_vertex_idx], np_dedup_vertices[polygon_vertex_idx[0]][None,:]])\n",
    "    is_midpoint_inpolygon = celeri.inpolygon(segment_current_block.mid_lon_plate_carree.values + longitude_east_offset,\n",
    "                                segment_current_block.mid_lat_plate_carree.values,\n",
    "                                vertices_current_block[:, 0], vertices_current_block[:, 1])\n",
    "    correct_east_labels[current_block_idx[np.where(is_midpoint_inpolygon == True)]] = current_block_label\n",
    "    correct_west_labels[current_block_idx[np.where(is_midpoint_inpolygon == False)]] = current_block_label\n",
    "\n",
    "# Find unprocessed indices\n",
    "unprocessed_idx = np.union1d(np.where(correct_east_labels == unprocessed_value),\n",
    "                             np.where(correct_west_labels == unprocessed_value))\n",
    "\n",
    "# plt.figure()\n",
    "# plt.title(\"Segment indices\")\n",
    "# for i in range(len(segment)):\n",
    "#     plt.plot([segment.lon1.values[i], segment.lon2.values[i]],\n",
    "#              [segment.lat1.values[i], segment.lat2.values[i]], \"-k\")\n",
    "#     plt.text(segment.mid_lon_plate_carree.values[i] - 0.25,\n",
    "#              segment.mid_lat_plate_carree.values[i],\n",
    "#              str(i), fontsize=6)\n",
    "\n",
    "plt.figure()\n",
    "plt.title(\"Initial labels\")\n",
    "for i in range(len(segment)):\n",
    "    plt.plot([segment.lon1.values[i], segment.lon2.values[i]],\n",
    "             [segment.lat1.values[i], segment.lat2.values[i]], \"-k\")\n",
    "    plt.text(segment.mid_lon_plate_carree.values[i] - 0.25,\n",
    "             segment.mid_lat_plate_carree.values[i],\n",
    "             str(segment.initial_label1[i]), fontsize=16)\n",
    "    plt.text(segment.mid_lon_plate_carree.values[i] + 0.25,\n",
    "             segment.mid_lat_plate_carree.values[i],\n",
    "             str(segment.initial_label2[i]), fontsize=16)\n",
    "\n",
    "plt.figure()\n",
    "plt.title(\"Attempt at east and west labels\")\n",
    "for i in range(len(segment)):\n",
    "    plt.plot([segment.lon1.values[i], segment.lon2.values[i]],\n",
    "             [segment.lat1.values[i], segment.lat2.values[i]], \"-k\")\n",
    "    plt.text(segment.mid_lon_plate_carree.values[i] - 0.25,\n",
    "             segment.mid_lat_plate_carree.values[i],\n",
    "             str(correct_west_labels[i]), fontsize=6)\n",
    "    plt.text(segment.mid_lon_plate_carree.values[i] + 0.25,\n",
    "             segment.mid_lat_plate_carree.values[i],\n",
    "             str(correct_east_labels[i]), fontsize=6)\n",
    "\n",
    "for i in range(len(nan_idx)):\n",
    "    plt.plot([segment.lon1.values[nan_idx[i]], segment.lon2.values[nan_idx[i]]],\n",
    "             [segment.lat1.values[nan_idx[i]], segment.lat2.values[nan_idx[i]]], \"-r\")\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "correct_east_labels[1] == 99"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "749f0fc94df05971c9b3f3660cf19264b2aeee03fc6d4bf75e86fd251d69cf68"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.8 64-bit ('base': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}